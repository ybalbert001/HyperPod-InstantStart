const express = require('express');
const cors = require('cors');
const WebSocket = require('ws');
const { exec, spawn } = require('child_process');
const fs = require('fs-extra');
const YAML = require('yaml');
const path = require('path');
const https = require('https');
const http = require('http');

// ÂºïÂÖ•ÈõÜÁæ§Áä∂ÊÄÅV2Ê®°Âùó
const { 
  handleClusterStatusV2, 
  handleClearCache, 
  handleCacheStatus 
} = require('./clusterStatusV2');

// ÂºïÂÖ•Â∫îÁî®Áä∂ÊÄÅV2Ê®°Âùó
const {
  handlePodsV2,
  handleServicesV2,
  handleAppStatusV2,
  handleClearAppCache,
  handleAppCacheStatus
} = require('./appStatusV2');

const app = express();
const PORT = 3001;
const WS_PORT = 8081; // Êîπ‰∏∫8081ÈÅøÂÖçÁ´ØÂè£ÂÜ≤Á™Å

app.use(cors());
app.use(express.json());

// WebSocketÊúçÂä°Âô®Áî®‰∫éÂÆûÊó∂Êõ¥Êñ∞
const wss = new WebSocket.Server({ port: WS_PORT });

// Â≠òÂÇ®Ê¥ªË∑ÉÁöÑÊó•ÂøóÊµÅ
const activeLogStreams = new Map();

// Êó•ÂøóÂ≠òÂÇ®ÈÖçÁΩÆ - ÁÆÄÂåñË∑ØÂæÑÁªìÊûÑ
const LOGS_BASE_DIR = path.join(__dirname, '..', 'logs');

// Á°Æ‰øùÊó•ÂøóÁõÆÂΩïÂ≠òÂú® - ÁÆÄÂåñÁâàÊú¨ÔºåÁõ¥Êé•‰ΩøÁî®‰ªªÂä°Âêç
function ensureLogDirectory(jobName, podName) {
  const jobLogDir = path.join(LOGS_BASE_DIR, jobName);
  if (!fs.existsSync(jobLogDir)) {
    fs.mkdirSync(jobLogDir, { recursive: true });
  }
  return path.join(jobLogDir, `${podName}.log`);
}

// ÂπøÊí≠Ê∂àÊÅØÁªôÊâÄÊúâËøûÊé•ÁöÑÂÆ¢Êà∑Á´Ø
function broadcast(data) {
  wss.clients.forEach(client => {
    if (client.readyState === WebSocket.OPEN) {
      client.send(JSON.stringify(data));
    }
  });
}

// ‰ºòÂåñÈîôËØØÊ∂àÊÅØÁöÑÂáΩÊï∞
function optimizeErrorMessage(errorMessage) {
  if (!errorMessage) return 'Unknown error';
  
  // Â¶ÇÊûúÊòØËé∑Âèñhyperpodpytorchjob‰ΩÜËµÑÊ∫êÁ±ªÂûã‰∏çÂ≠òÂú®ÔºåËøôÊòØÊ≠£Â∏∏ÊÉÖÂÜµ
  if (errorMessage.includes(`doesn't have a resource type "hyperpodpytorchjob"`)) {
    return 'No HyperPod training jobs found (HyperPod operator may not be installed)';
  }
  // Â¶ÇÊûúÊòØËé∑Âèñrayjob‰ΩÜËµÑÊ∫êÁ±ªÂûã‰∏çÂ≠òÂú®
  if (errorMessage.includes(`doesn't have a resource type "rayjob"`)) {
    return 'No RayJobs found (Ray operator may not be installed)';
  }
  // Â¶ÇÊûúÊòØËµÑÊ∫ê‰∏çÂ≠òÂú®Ôºå‰ΩøÁî®Êõ¥ÂèãÂ•ΩÁöÑÊ∂àÊÅØ
  if (errorMessage.includes('not found') || errorMessage.includes('NotFound')) {
    return 'Resource not found - this may be normal if no resources have been created yet';
  }
  // Â¶ÇÊûúÊòØËøûÊé•ÈóÆÈ¢ò
  if (errorMessage.includes('connection refused') || errorMessage.includes('unable to connect')) {
    return 'Unable to connect to Kubernetes cluster. Please check if the cluster is accessible.';
  }
  
  return errorMessage;
}

// ÊâßË°åkubectlÂëΩ‰ª§ÁöÑËæÖÂä©ÂáΩÊï∞ - ÁÆÄÂåñÁâàÈîôËØØ‰ºòÂåñ
function executeKubectl(command, timeout = 30000) { // ÈªòËÆ§30ÁßíË∂ÖÊó∂
  return new Promise((resolve, reject) => {
    console.log(`Executing kubectl command: kubectl ${command}`);
    
    const child = exec(`kubectl ${command}`, { timeout }, (error, stdout, stderr) => {
      if (error) {
        console.error(`kubectl command failed: kubectl ${command}`);
        console.error(`Error details:`, error);
        console.error(`Stderr:`, stderr);
        
        if (error.code === 'ETIMEDOUT') {
          console.error(`kubectl command timed out after ${timeout}ms: ${command}`);
          reject(new Error(`Command timed out after ${timeout/1000} seconds. The cluster may be slow to respond.`));
        } else {
          const errorMessage = error.message || stderr || 'Unknown kubectl error';
          
          // ÈíàÂØπÁâπÂÆöÊÉÖÂÜµ‰ºòÂåñÈîôËØØÊ∂àÊÅØ
          let optimizedMessage = errorMessage;
          
          // Â¶ÇÊûúÊòØËé∑Âèñhyperpodpytorchjob‰ΩÜËµÑÊ∫êÁ±ªÂûã‰∏çÂ≠òÂú®ÔºåËøôÊòØÊ≠£Â∏∏ÊÉÖÂÜµ
          if (command.includes('get hyperpodpytorchjob') && 
              errorMessage.includes(`doesn't have a resource type "hyperpodpytorchjob"`)) {
            optimizedMessage = 'No HyperPod training jobs found (HyperPod operator may not be installed)';
          }
          // Â¶ÇÊûúÊòØËµÑÊ∫ê‰∏çÂ≠òÂú®Ôºå‰ΩøÁî®Êõ¥ÂèãÂ•ΩÁöÑÊ∂àÊÅØ
          else if (errorMessage.includes('not found') || errorMessage.includes('NotFound')) {
            optimizedMessage = 'Resource not found - this may be normal if no resources have been created yet';
          }
          // Â¶ÇÊûúÊòØËøûÊé•ÈóÆÈ¢ò
          else if (errorMessage.includes('connection refused') || errorMessage.includes('unable to connect')) {
            optimizedMessage = 'Unable to connect to Kubernetes cluster. Please check if the cluster is accessible.';
          }
          
          console.error(`Optimized error message: ${optimizedMessage}`);
          reject(new Error(optimizedMessage));
        }
      } else {
        console.log(`kubectl command succeeded: kubectl ${command}`);
        console.log(`Output:`, stdout);
        resolve(stdout);
      }
    });
    
    // È¢ùÂ§ñÁöÑË∂ÖÊó∂‰øùÊä§
    const timeoutId = setTimeout(() => {
      child.kill('SIGTERM');
      console.error(`Force killing kubectl command after ${timeout}ms: ${command}`);
    }, timeout);
    
    child.on('exit', () => {
      clearTimeout(timeoutId);
    });
  });
}

// ÁÆÄÂåñÁöÑÊ®°ÂûãÊ†áÁ≠æÁîüÊàêÂáΩÊï∞ÔºàÁî®‰∫éÊ®°Âûã‰∏ãËΩΩÔºâ
function generateModelTag(modelId) {
  if (!modelId) return 'model';
  return modelId
    .toLowerCase()
    .replace(/[^a-z0-9-]/g, '-')
    .replace(/-+/g, '-')
    .replace(/^-|-$/g, '') || 'model';
}

// ÁîüÊàêNLBÊ≥®Ëß£ÁöÑÂáΩÊï∞
function generateNLBAnnotations(isExternal) {
  if (isExternal) {
    return `
    service.beta.kubernetes.io/aws-load-balancer-type: "external"
    service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: "ip"
    service.beta.kubernetes.io/aws-load-balancer-scheme: "internet-facing"
    service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: "true"`;
  } else {
    return `
    service.beta.kubernetes.io/aws-load-balancer-type: "external"
    service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: "ip"
    service.beta.kubernetes.io/aws-load-balancer-scheme: "internal"
    service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: "true"`;
  }
}

// ÁÆÄÂåñÁöÑÂëΩ‰ª§Ëß£ÊûêÂáΩÊï∞ - ÁßªÈô§GPUËá™Âä®Ëß£ÊûêÈÄªËæë
function parseVllmCommand(vllmCommandString) {
  // ÁßªÈô§Êç¢Ë°åÁ¨¶ÂíåÂ§ö‰ΩôÁ©∫Ê†ºÔºåÂ§ÑÁêÜÂèçÊñúÊù†Êç¢Ë°å
  const cleanCommand = vllmCommandString
    .replace(/\\\s*\n/g, ' ')  // Â§ÑÁêÜÂèçÊñúÊù†Êç¢Ë°å
    .replace(/\s+/g, ' ')      // ÂêàÂπ∂Â§ö‰∏™Á©∫Ê†º
    .trim();
  
  // ÂàÜÂâ≤ÂëΩ‰ª§‰∏∫Êï∞ÁªÑ
  const parts = cleanCommand.split(' ').filter(part => part.trim());
  
  // Ê£ÄÊü•ÂëΩ‰ª§ÊòØÂê¶‰∏∫Á©∫
  if (parts.length === 0) {
    throw new Error('Command cannot be empty');
  }
  
  // Ê£ÄÊü•ÊòØÂê¶‰∏∫Â∑≤Áü•ÁöÑÂëΩ‰ª§Ê†ºÂºèÔºàÁî®‰∫éÊ°ÜÊû∂ËØÜÂà´Ôºâ
  const isVllmCommand = parts.includes('python3') && parts.includes('-m') && parts.includes('vllm.entrypoints.openai.api_server');
  const isVllmServeCommand = parts.includes('vllm') && parts.includes('serve');
  const isSglangCommand = parts.includes('python3') && parts.includes('-m') && parts.includes('sglang.launch_server');
  
  let entrypointIndex = -1;
  
  if (isVllmCommand) {
    entrypointIndex = parts.findIndex(part => part === 'vllm.entrypoints.openai.api_server');
  } else if (isVllmServeCommand) {
    entrypointIndex = parts.findIndex(part => part === 'serve');
  } else if (isSglangCommand) {
    entrypointIndex = parts.findIndex(part => part === 'sglang.launch_server');
  }
  
  const args = entrypointIndex >= 0 ? parts.slice(entrypointIndex + 1) : parts.slice(1);
  
  return {
    fullCommand: parts,
    args: args,
    commandType: (isVllmCommand || isVllmServeCommand) ? 'vllm' : (isSglangCommand ? 'sglang' : 'custom')
  };
}

// ÊîπËøõÁöÑHTTPËØ∑Ê±Ç‰ª£ÁêÜÂáΩÊï∞
function makeHttpRequest(url, payload, method = 'POST') {
  return new Promise((resolve, reject) => {
    try {
      const urlObj = new URL(url);
      const isHttps = urlObj.protocol === 'https:';
      const httpModule = isHttps ? https : http;
      
      const isGetRequest = method.toUpperCase() === 'GET';
      const postData = isGetRequest ? '' : JSON.stringify(payload);
      
      const options = {
        hostname: urlObj.hostname,
        port: urlObj.port || (isHttps ? 443 : 80),
        path: urlObj.pathname + urlObj.search,
        method: method.toUpperCase(),
        headers: {
          'User-Agent': 'Model-Deployment-UI/1.0'
        },
        timeout: 30000 // 30ÁßíË∂ÖÊó∂
      };
      
      // Âè™ÊúâPOSTËØ∑Ê±ÇÊâçÈúÄË¶ÅContent-TypeÂíåContent-Length
      if (!isGetRequest) {
        options.headers['Content-Type'] = 'application/json';
        options.headers['Content-Length'] = Buffer.byteLength(postData);
      }
      
      console.log(`Making HTTP ${method} request to: ${url}`);
      console.log(`Request options:`, JSON.stringify(options, null, 2));
      if (!isGetRequest) {
        console.log(`Payload:`, postData);
      }
      
      const req = httpModule.request(options, (res) => {
        let data = '';
        
        console.log(`Response status: ${res.statusCode}`);
        console.log(`Response headers:`, JSON.stringify(res.headers, null, 2));
        
        res.on('data', (chunk) => {
          data += chunk;
        });
        
        res.on('end', () => {
          console.log(`Response data:`, data);
          
          // Â§ÑÁêÜ‰∏çÂêåÁöÑÂìçÂ∫îÁä∂ÊÄÅ
          if (res.statusCode >= 200 && res.statusCode < 300) {
            // ÊàêÂäüÂìçÂ∫î
            try {
              const jsonData = JSON.parse(data);
              resolve({
                success: true,
                status: res.statusCode,
                data: jsonData
              });
            } catch (parseError) {
              // Â¶ÇÊûú‰∏çÊòØJSONÔºåËøîÂõûÂéüÂßãÊñáÊú¨
              console.log('Response is not JSON, returning as text');
              resolve({
                success: true,
                status: res.statusCode,
                data: data,
                isText: true
              });
            }
          } else {
            // ÈîôËØØÂìçÂ∫î
            try {
              const errorData = JSON.parse(data);
              resolve({
                success: false,
                status: res.statusCode,
                error: errorData.error || `HTTP ${res.statusCode}`,
                data: errorData
              });
            } catch (parseError) {
              resolve({
                success: false,
                status: res.statusCode,
                error: `HTTP ${res.statusCode}: ${data}`,
                data: data
              });
            }
          }
        });
      });
      
      req.on('error', (error) => {
        console.error('HTTP request error:', error);
        reject({
          success: false,
          error: `Network error: ${error.message}`
        });
      });
      
      req.on('timeout', () => {
        console.error('HTTP request timeout');
        req.destroy();
        reject({
          success: false,
          error: 'Request timeout (30s)'
        });
      });
      
      // Âè™ÊúâÈùûGETËØ∑Ê±ÇÊâçÂÜôÂÖ•payload
      if (!isGetRequest && postData) {
        req.write(postData);
      }
      req.end();
      
    } catch (error) {
      console.error('HTTP request setup error:', error);
      reject({
        success: false,
        error: `Request setup error: ${error.message}`
      });
    }
  });
}

// Ëé∑ÂèñPending GPUÁªüËÆ°
app.get('/api/pending-gpus', async (req, res) => {
  try {
    const pendingPodsOutput = await executeKubectl('get pods --field-selector status.phase=Pending -o json');
    const pendingPodsData = JSON.parse(pendingPodsOutput);
    
    let pendingGPUs = 0;
    if (pendingPodsData.items && Array.isArray(pendingPodsData.items)) {
      pendingGPUs = pendingPodsData.items.reduce((sum, pod) => {
        if (pod.spec?.containers) {
          return sum + pod.spec.containers.reduce((containerSum, container) => {
            const gpuRequest = container.resources?.requests?.['nvidia.com/gpu'];
            return containerSum + (parseInt(gpuRequest) || 0);
          }, 0);
        }
        return sum;
      }, 0);
    }
    
    res.json({ pendingGPUs });
  } catch (error) {
    console.error('Error fetching pending GPUs:', error);
    res.status(500).json({ error: error.message, pendingGPUs: 0 });
  }
});

// Ëé∑ÂèñÈõÜÁæ§ËäÇÁÇπGPU‰ΩøÁî®ÊÉÖÂÜµ - V2‰ºòÂåñÁâàÊú¨
app.get('/api/cluster-status', handleClusterStatusV2);

// ÈõÜÁæ§Áä∂ÊÄÅÁºìÂ≠òÁÆ°ÁêÜAPI
app.post('/api/cluster-status/clear-cache', handleClearCache);
app.get('/api/cluster-status/cache-status', handleCacheStatus);

// Áªü‰∏ÄÊó•ÂøóÊµÅÁÆ°ÁêÜ - ÈÅøÂÖçÂÜ≤Á™Å
const unifiedLogStreams = new Map(); // Áªü‰∏ÄÁÆ°ÁêÜÊâÄÊúâÊó•ÂøóÊµÅ

// ÂêØÂä®Áªü‰∏ÄÊó•ÂøóÊµÅÔºàÊîØÊåÅËá™Âä®Êî∂ÈõÜÂíåWebSocketÊµÅÂºè‰º†ËæìÔºâ
function startUnifiedLogStream(jobName, podName, options = {}) {
  const streamKey = `${jobName}-${podName}`;
  const { ws = null, autoCollection = false } = options;
  
  // Â¶ÇÊûúÂ∑≤ÁªèÊúâËØ•podÁöÑÊó•ÂøóÊµÅÔºåÊ∑ªÂä†WebSocketËøûÊé•‰ΩÜ‰∏çÈáçÂêØËøõÁ®ã
  if (unifiedLogStreams.has(streamKey)) {
    const existing = unifiedLogStreams.get(streamKey);
    if (ws && !existing.webSockets.has(ws)) {
      existing.webSockets.add(ws);
      console.log(`Added WebSocket to existing log stream for ${streamKey}`);
      
      // ÂèëÈÄÅËøûÊé•ÊàêÂäüÊ∂àÊÅØ
      if (ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({
          type: 'log_stream_started',
          jobName: jobName,
          podName: podName,
          timestamp: new Date().toISOString()
        }));
      }
    }
    return;
  }
  
  console.log(`üöÄ Starting unified log stream for pod: ${podName} in job: ${jobName} (auto: ${autoCollection})`);
  
  // ÂàõÂª∫Êó•ÂøóÊñá‰ª∂Ë∑ØÂæÑ
  const logFilePath = ensureLogDirectory(jobName, podName);
  const logStream = fs.createWriteStream(logFilePath, { flags: 'a' });
  
  // ÂêØÂä®kubectl logsÂëΩ‰ª§
  const logProcess = spawn('kubectl', ['logs', '-f', podName], {
    stdio: ['pipe', 'pipe', 'pipe']
  });
  
  // ÂàõÂª∫WebSocketÈõÜÂêà
  const webSockets = new Set();
  if (ws) {
    webSockets.add(ws);
  }
  
  // Â≠òÂÇ®Áªü‰∏ÄÁöÑÊó•ÂøóÊµÅ‰ø°ÊÅØ
  unifiedLogStreams.set(streamKey, {
    process: logProcess,
    logStream: logStream,
    webSockets: webSockets,
    jobName: jobName,
    podName: podName,
    autoCollection: autoCollection,
    startTime: new Date().toISOString()
  });
  
  // Â§ÑÁêÜÊ†áÂáÜËæìÂá∫
  logProcess.stdout.on('data', (data) => {
    const logLine = data.toString();
    const timestamp = new Date().toISOString();
    
    // ÂÜôÂÖ•Êñá‰ª∂ÔºàÂ∏¶Êó∂Èó¥Êà≥Ôºâ
    logStream.write(`[${timestamp}] ${logLine}`);
    
    // ÂèëÈÄÅÂà∞ÊâÄÊúâËøûÊé•ÁöÑWebSocket
    webSockets.forEach(socket => {
      if (socket.readyState === WebSocket.OPEN) {
        socket.send(JSON.stringify({
          type: 'log_data',
          jobName: jobName,
          podName: podName,
          data: logLine,
          timestamp: timestamp
        }));
      }
    });
  });
  
  // Â§ÑÁêÜÈîôËØØËæìÂá∫
  logProcess.stderr.on('data', (data) => {
    const errorLine = data.toString();
    const timestamp = new Date().toISOString();
    
    // ÂÜôÂÖ•Êñá‰ª∂
    logStream.write(`[${timestamp}] ERROR: ${errorLine}`);
    
    // ÂèëÈÄÅÈîôËØØÂà∞WebSocket
    webSockets.forEach(socket => {
      if (socket.readyState === WebSocket.OPEN) {
        socket.send(JSON.stringify({
          type: 'log_error',
          jobName: jobName,
          podName: podName,
          error: errorLine,
          timestamp: timestamp
        }));
      }
    });
  });
  
  // Â§ÑÁêÜËøõÁ®ãÈÄÄÂá∫
  logProcess.on('close', (code) => {
    console.log(`Unified log stream for ${podName} exited with code ${code}`);
    logStream.end();
    
    // ÈÄöÁü•ÊâÄÊúâWebSocketËøûÊé•
    webSockets.forEach(socket => {
      if (socket.readyState === WebSocket.OPEN) {
        socket.send(JSON.stringify({
          type: 'log_stream_closed',
          jobName: jobName,
          podName: podName,
          timestamp: new Date().toISOString()
        }));
      }
    });
    
    unifiedLogStreams.delete(streamKey);
  });
  
  // Â§ÑÁêÜËøõÁ®ãÈîôËØØ
  logProcess.on('error', (error) => {
    console.error(`Unified log stream error for ${podName}:`, error);
    logStream.end();
    
    // ÈÄöÁü•ÊâÄÊúâWebSocketËøûÊé•
    webSockets.forEach(socket => {
      if (socket.readyState === WebSocket.OPEN) {
        socket.send(JSON.stringify({
          type: 'log_stream_error',
          jobName: jobName,
          podName: podName,
          error: error.message,
          timestamp: new Date().toISOString()
        }));
      }
    });
    
    unifiedLogStreams.delete(streamKey);
  });
  
  // ÂèëÈÄÅÂêØÂä®ÊàêÂäüÊ∂àÊÅØ
  if (ws && ws.readyState === WebSocket.OPEN) {
    ws.send(JSON.stringify({
      type: 'log_stream_started',
      jobName: jobName,
      podName: podName,
      timestamp: new Date().toISOString()
    }));
  }
}

// ‰ªéÁªü‰∏ÄÊó•ÂøóÊµÅ‰∏≠ÁßªÈô§WebSocketËøûÊé•
function removeWebSocketFromLogStream(ws, jobName, podName) {
  const streamKey = `${jobName}-${podName}`;
  const stream = unifiedLogStreams.get(streamKey);
  
  if (stream) {
    stream.webSockets.delete(ws);
    console.log(`Removed WebSocket from log stream ${streamKey}, remaining: ${stream.webSockets.size}`);
    
    // Â¶ÇÊûúÊ≤°ÊúâWebSocketËøûÊé•‰∏î‰∏çÊòØËá™Âä®Êî∂ÈõÜÔºåÂÅúÊ≠¢Êó•ÂøóÊµÅ
    if (stream.webSockets.size === 0 && !stream.autoCollection) {
      console.log(`No more WebSocket connections for ${streamKey}, stopping log stream`);
      stream.process.kill();
      stream.logStream.end();
      unifiedLogStreams.delete(streamKey);
    }
  }
}

// ‰∏∫ËÆ≠ÁªÉ‰ªªÂä°Ëá™Âä®ÂºÄÂßãÊó•ÂøóÊî∂ÈõÜ
async function startAutoLogCollectionForJob(jobName) {
  try {
    console.log(`üîç Starting auto log collection for training job: ${jobName}`);
    
    // Ëé∑ÂèñËØ•ËÆ≠ÁªÉ‰ªªÂä°ÁöÑÊâÄÊúâpods
    const output = await executeKubectl('get pods -o json');
    const result = JSON.parse(output);
    
    const jobPods = result.items.filter(pod => {
      const labels = pod.metadata.labels || {};
      const ownerReferences = pod.metadata.ownerReferences || [];
      
      return labels['training-job-name'] === jobName || 
             labels['app'] === jobName ||
             ownerReferences.some(ref => ref.name === jobName) ||
             pod.metadata.name.includes(jobName);
    });
    
    // ‰∏∫ÊØè‰∏™ËøêË°å‰∏≠ÁöÑpodÂºÄÂßãËá™Âä®Êó•ÂøóÊî∂ÈõÜ
    jobPods.forEach(pod => {
      if (pod.status.phase === 'Running' || pod.status.phase === 'Pending') {
        startUnifiedLogStream(jobName, pod.metadata.name, { autoCollection: true });
      }
    });
    
    console.log(`‚úÖ Started auto log collection for ${jobPods.length} pods in job ${jobName}`);
  } catch (error) {
    console.error(`‚ùå Failed to start auto log collection for job ${jobName}:`, error);
  }
}

// ‰øÆÊîπÂéüÊúâÁöÑstartLogStreamÂáΩÊï∞Ôºå‰ΩøÁî®Áªü‰∏ÄÁÆ°ÁêÜ
function startLogStream(ws, jobName, podName) {
  startUnifiedLogStream(jobName, podName, { ws: ws });
}

// ‰øÆÊîπÂéüÊúâÁöÑstopLogStreamÂáΩÊï∞
function stopLogStream(ws, jobName, podName) {
  removeWebSocketFromLogStream(ws, jobName, podName);
  
  if (ws.readyState === WebSocket.OPEN) {
    ws.send(JSON.stringify({
      type: 'log_stream_stopped',
      jobName: jobName,
      podName: podName,
      timestamp: new Date().toISOString()
    }));
  }
}

// Â∫îÁî®Áä∂ÊÄÅV2 API - ‰ºòÂåñÁâàÊú¨
app.get('/api/v2/pods', handlePodsV2);
app.get('/api/v2/services', handleServicesV2);
app.get('/api/v2/app-status', handleAppStatusV2);
app.post('/api/v2/app-status/clear-cache', handleClearAppCache);
app.get('/api/v2/app-status/cache-status', handleAppCacheStatus);

// Ëé∑ÂèñPodÁä∂ÊÄÅ
app.get('/api/pods', async (req, res) => {
  try {
    console.log('Fetching pods...');
    const output = await executeKubectl('get pods -o json');
    const pods = JSON.parse(output);
    console.log('Pods fetched:', pods.items.length, 'pods');
    res.json(pods.items);
  } catch (error) {
    console.error('Pods fetch error:', error);
    res.status(500).json({ error: error.message });
  }
});

// Ëé∑ÂèñServiceÁä∂ÊÄÅ
app.get('/api/services', async (req, res) => {
  try {
    console.log('Fetching services...');
    const output = await executeKubectl('get services -o json');
    const services = JSON.parse(output);
    console.log('Services fetched:', services.items.length, 'services');
    res.json(services.items);
  } catch (error) {
    console.error('Services fetch error:', error);
    res.status(500).json({ error: error.message });
  }
});

// ‰ª£ÁêÜHTTPËØ∑Ê±ÇÂà∞Ê®°ÂûãÊúçÂä°
app.post('/api/proxy-request', async (req, res) => {
  try {
    const { url, payload, method = 'POST' } = req.body;
    
    if (!url) {
      return res.status(400).json({
        success: false,
        error: 'Missing url'
      });
    }
    
    // GETËØ∑Ê±Ç‰∏çÈúÄË¶Åpayload
    if (method.toUpperCase() !== 'GET' && payload === undefined) {
      return res.status(400).json({
        success: false,
        error: 'Missing payload for non-GET request'
      });
    }
    
    console.log(`Proxying ${method} request to: ${url}`);
    if (method.toUpperCase() !== 'GET') {
      console.log(`Payload:`, JSON.stringify(payload, null, 2));
    }
    
    const result = await makeHttpRequest(url, payload, method);
    
    console.log('Proxy result:', JSON.stringify(result, null, 2));
    res.json(result);
    
  } catch (error) {
    console.error('Proxy request error:', error);
    res.json({
      success: false,
      error: error.error || error.message || 'Request failed'
    });
  }
});

// ÁîüÊàêÂπ∂ÈÉ®ÁΩ≤YAMLÈÖçÁΩÆ - ‰ªÖÁî®‰∫éÊé®ÁêÜÈÉ®ÁΩ≤ÔºàVLLMÂíåOllamaÔºâ
app.post('/api/deploy', async (req, res) => {
  try {
    const {
      replicas,
      huggingFaceToken,
      deploymentType,
      vllmCommand,
      ollamaModelId,
      gpuCount,
      isExternal = true,
      deploymentName,  // Áî®Êà∑ËæìÂÖ•ÁöÑÈÉ®ÁΩ≤ÂêçÁß∞
      dockerImage = 'vllm/vllm-openai:latest'
    } = req.body;

    console.log('Inference deployment request:', { 
      deploymentType, 
      deploymentName,
      ollamaModelId, 
      replicas, 
      isExternal,
      dockerImage
    });

    // ÁîüÊàêÂ∏¶Êó∂Èó¥Êà≥ÁöÑÂîØ‰∏ÄÊ†áÁ≠æÔºàÁ¨¶ÂêàKubernetesÂëΩÂêçËßÑËåÉÔºâ
    const timestamp = new Date().toISOString()
      .replace(/[:.]/g, '-')     // ÊõøÊç¢ÂÜíÂè∑ÂíåÁÇπÂè∑‰∏∫ËøûÂ≠óÁ¨¶
      .replace('T', '-')         // ÊõøÊç¢T‰∏∫ËøûÂ≠óÁ¨¶
      .slice(0, 19);             // Êà™ÂèñÂà∞ÁßíÁ∫ß
    const finalDeploymentTag = deploymentName ? `${deploymentName}-${timestamp}` : `model-${timestamp}`;
    
    console.log(`Generated deployment tag: "${finalDeploymentTag}"`);

    let templatePath, newYamlContent;

    // ÁîüÊàêNLBÊ≥®Ëß£
    const nlbAnnotations = generateNLBAnnotations(isExternal);
    console.log(`Generated NLB annotations (external: ${isExternal}):`, nlbAnnotations);

    if (deploymentType === 'ollama') {
      // Â§ÑÁêÜOllamaÈÉ®ÁΩ≤
      templatePath = path.join(__dirname, '../templates/ollama-template.yaml');
      const templateContent = await fs.readFile(templatePath, 'utf8');
      
      // ÊõøÊç¢Ê®°Êùø‰∏≠ÁöÑÂç†‰ΩçÁ¨¶
      newYamlContent = templateContent
        .replace(/MODEL_TAG/g, finalDeploymentTag)
        .replace(/OLLAMA_MODEL_ID/g, ollamaModelId)
        .replace(/REPLICAS_COUNT/g, replicas.toString())
        .replace(/GPU_COUNT/g, gpuCount.toString())
        .replace(/NLB_ANNOTATIONS/g, nlbAnnotations);
      
    } else {
      // Â§ÑÁêÜVLLM/SGLang/CustomÈÉ®ÁΩ≤
      const parsedCommand = parseVllmCommand(vllmCommand);
      console.log('Parsed command:', parsedCommand);
      
      // Ê†πÊçÆÂëΩ‰ª§Á±ªÂûãÁ°ÆÂÆöÊúçÂä°ÂºïÊìéÂâçÁºÄ
      let servEngine;
      if (parsedCommand.commandType === 'sglang') {
        servEngine = 'sglang';
      } else if (parsedCommand.commandType === 'vllm') {
        servEngine = 'vllm';
      } else {
        servEngine = 'custom';  // Ëá™ÂÆö‰πâÂëΩ‰ª§‰ΩøÁî®customÂâçÁºÄ
      }
      console.log(`Using service engine: ${servEngine} for command type: ${parsedCommand.commandType}`);

      templatePath = path.join(__dirname, '../templates/vllm-sglang-template.yaml');
      const templateContent = await fs.readFile(templatePath, 'utf8');
      
      // ÁîüÊàêHuggingFace tokenÁéØÂ¢ÉÂèòÈáèÔºàÂ¶ÇÊûúÊèê‰æõ‰∫ÜtokenÔºâ
      let hfTokenEnv = '';
      if (huggingFaceToken && huggingFaceToken.trim() !== '') {
        hfTokenEnv = `
            - name: HUGGING_FACE_HUB_TOKEN
              value: "${huggingFaceToken}"`;
      }
      
      // ÊõøÊç¢Ê®°Êùø‰∏≠ÁöÑÂç†‰ΩçÁ¨¶ - ‰ΩøÁî®Áî®Êà∑ÊåáÂÆöÁöÑGPUÊï∞Èáè
      newYamlContent = templateContent
        .replace(/SERVENGINE/g, servEngine)
        .replace(/MODEL_TAG/g, finalDeploymentTag)
        .replace(/REPLICAS_COUNT/g, replicas.toString())
        .replace(/GPU_COUNT/g, gpuCount.toString())
        .replace(/HF_TOKEN_ENV/g, hfTokenEnv)
        .replace(/VLLM_COMMAND/g, JSON.stringify(parsedCommand.fullCommand))
        .replace(/DOCKER_IMAGE/g, dockerImage)
        .replace(/NLB_ANNOTATIONS/g, nlbAnnotations);
    }
    
    // ‰øùÂ≠òÂà∞È°πÁõÆÁõÆÂΩï‰∏≠ÁöÑdeploymentsÊñá‰ª∂Â§π
    const deploymentsDir = path.join(__dirname, '../deployments');
    await fs.ensureDir(deploymentsDir);
    
    const accessType = isExternal ? 'external' : 'internal';
    const tempYamlPath = path.join(deploymentsDir, `${finalDeploymentTag}-${deploymentType}-${accessType}.yaml`);
    await fs.writeFile(tempYamlPath, newYamlContent);
    
    console.log(`Generated YAML saved to: ${tempYamlPath}`);
    
    // ÊâßË°åkubectl apply
    const applyOutput = await executeKubectl(`apply -f ${tempYamlPath}`);
    
    // ÂπøÊí≠ÈÉ®ÁΩ≤Áä∂ÊÄÅÊõ¥Êñ∞
    broadcast({
      type: 'deployment',
      status: 'success',
      message: `Successfully deployed: ${finalDeploymentTag} (${accessType} access)`,
      output: applyOutput
    });
    
    res.json({
      success: true,
      message: 'Deployment successful',
      output: applyOutput,
      yamlPath: tempYamlPath,
      generatedYaml: newYamlContent,
      deploymentType,
      deploymentTag: finalDeploymentTag,
      accessType
    });
    
  } catch (error) {
    console.error('Deployment error:', error);
    
    broadcast({
      type: 'deployment',
      status: 'error',
      message: `Deployment failed: ${error.message}`
    });
    
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// Áªü‰∏ÄÁöÑËÆ≠ÁªÉYAMLÈÉ®ÁΩ≤ÂáΩÊï∞
async function deployTrainingYaml(recipeType, jobName, yamlContent) {
  try {
    // Á°Æ‰øùtempÁõÆÂΩïÂ≠òÂú®
    const tempDir = path.join(__dirname, '../temp');
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }

    // Á°Æ‰øùdeployments/trainingsÁõÆÂΩïÂ≠òÂú®
    const trainingsDir = path.join(__dirname, '../deployments/trainings');
    if (!fs.existsSync(trainingsDir)) {
      fs.mkdirSync(trainingsDir, { recursive: true });
    }

    // ÂÜôÂÖ•‰∏¥Êó∂Êñá‰ª∂ÔºàÁî®‰∫ékubectl applyÔºâ
    const tempFileName = `${recipeType}-${jobName}-${Date.now()}.yaml`;
    const tempFilePath = path.join(tempDir, tempFileName);
    await fs.writeFile(tempFilePath, yamlContent);

    // ÂÜôÂÖ•Ê∞∏‰πÖÊñá‰ª∂ÔºàÁî®‰∫éËÆ∞ÂΩïÔºâ
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const permanentFileName = `${recipeType}_${timestamp}.yaml`;
    const permanentFilePath = path.join(trainingsDir, permanentFileName);
    await fs.writeFile(permanentFilePath, yamlContent);

    console.log(`${recipeType} training YAML saved to: ${permanentFilePath}`);

    // Â∫îÁî®YAMLÈÖçÁΩÆ
    const applyOutput = await executeKubectl(`apply -f ${tempFilePath}`);
    console.log(`${recipeType} training kubectl apply output:`, applyOutput);

    // Ê∏ÖÁêÜ‰∏¥Êó∂Êñá‰ª∂
    fs.unlinkSync(tempFilePath);

    // ÂèëÈÄÅWebSocketÂπøÊí≠
    broadcast({
      type: 'training_launch',
      status: 'success',
      message: `Successfully launched ${recipeType} training job: ${jobName}`,
      output: applyOutput
    });

    return {
      success: true,
      permanentFileName,
      permanentFilePath,
      applyOutput
    };

  } catch (error) {
    // ÂèëÈÄÅÈîôËØØÂπøÊí≠
    broadcast({
      type: 'training_launch',
      status: 'error',
      message: `${recipeType} training launch failed: ${error.message}`
    });

    throw error;
  }
}

// ÁîüÊàêÂπ∂ÈÉ®ÁΩ≤HyperPod TorchËÆ≠ÁªÉ‰ªªÂä° - ‰∏ìÈó®Áî®‰∫éTorchËÆ≠ÁªÉ
app.post('/api/launch-torch-training', async (req, res) => {
  try {
    console.log('Raw torch training request body:', JSON.stringify(req.body, null, 2));
    
    const {
      trainingJobName,
      dockerImage = '633205212955.dkr.ecr.us-west-2.amazonaws.com/sm-training-op-torch26-smhp-op:latest',
      instanceType = 'ml.g5.12xlarge',
      nprocPerNode = 1,
      replicas = 1,
      efaCount = 16,
      entryPythonScriptPath,
      pythonScriptParameters,
      mlflowTrackingUri = '',
      logMonitoringConfig
    } = req.body;

    console.log('Torch training launch request parsed:', { 
      trainingJobName,
      dockerImage,
      instanceType,
      nprocPerNode,
      replicas,
      efaCount,
      entryPythonScriptPath,
      pythonScriptParameters,
      mlflowTrackingUri,
      logMonitoringConfig: logMonitoringConfig ? 'present' : 'empty'
    });

    // È™åËØÅÂøÖÈúÄÂèÇÊï∞
    if (!trainingJobName) {
      return res.status(400).json({
        success: false,
        error: 'Training job name is required'
      });
    }

    if (!entryPythonScriptPath) {
      return res.status(400).json({
        success: false,
        error: 'Entry Python Script Path is required'
      });
    }

    if (!pythonScriptParameters) {
      return res.status(400).json({
        success: false,
        error: 'Python Script Parameters are required'
      });
    }

    // ËØªÂèñTorchËÆ≠ÁªÉ‰ªªÂä°Ê®°Êùø
    const templatePath = path.join(__dirname, '../templates/hyperpod-training-torch-template.yaml');
    const templateContent = await fs.readFile(templatePath, 'utf8');
    
    // Â§ÑÁêÜÊó•ÂøóÁõëÊéßÈÖçÁΩÆ
    let logMonitoringConfigYaml = '';
    if (logMonitoringConfig && logMonitoringConfig.trim() !== '') {
      // Ê∑ªÂä†ÈÄÇÂΩìÁöÑÁº©Ëøõ
      const indentedConfig = logMonitoringConfig
        .split('\n')
        .map(line => line.trim() ? `    ${line}` : line)
        .join('\n');
      logMonitoringConfigYaml = `
    logMonitoringConfiguration: 
${indentedConfig}`;
    }
    
    // Â§ÑÁêÜPythonËÑöÊú¨ÂèÇÊï∞ - Á°Æ‰øùÂ§öË°åÂèÇÊï∞Âú®YAML‰∏≠Ê≠£Á°ÆÊ†ºÂºèÂåñ
    let formattedPythonParams = pythonScriptParameters;
    if (pythonScriptParameters.includes('\\')) {
      // Â¶ÇÊûúÂåÖÂê´ÂèçÊñúÊù†Êç¢Ë°åÁ¨¶ÔºåÂ∞ÜÂÖ∂ËΩ¨Êç¢‰∏∫ÂçïË°åÊ†ºÂºè
      formattedPythonParams = pythonScriptParameters
        .replace(/\\\s*\n\s*/g, ' ')  // Â∞ÜÂèçÊñúÊù†Êç¢Ë°åÊõøÊç¢‰∏∫Á©∫Ê†º
        .replace(/\s+/g, ' ')         // ÂêàÂπ∂Â§ö‰∏™Á©∫Ê†º
        .trim();
    }
    
    // ÊõøÊç¢Ê®°Êùø‰∏≠ÁöÑÂç†‰ΩçÁ¨¶
    const newYamlContent = templateContent
      .replace(/TRAINING_JOB_NAME/g, trainingJobName)
      .replace(/DOCKER_IMAGE/g, dockerImage)
      .replace(/INSTANCE_TYPE/g, instanceType)
      .replace(/NPROC_PER_NODE/g, nprocPerNode.toString())
      .replace(/REPLICAS_COUNT/g, replicas.toString())
      .replace(/EFA_PER_NODE/g, efaCount.toString())
      .replace(/TORCH_RECIPE_PYPATH_PH/g, entryPythonScriptPath)
      .replace(/TORCH_RECIPE_PYPARAMS_PH/g, formattedPythonParams)
      .replace(/SM_MLFLOW_ARN/g, mlflowTrackingUri)
      .replace(/LOG_MONITORING_CONFIG/g, logMonitoringConfigYaml);

    console.log('Generated torch training YAML content:', newYamlContent);

    // ÁîüÊàêÊó∂Èó¥Êà≥
    const timestamp = Date.now();
    
    // ÁîüÊàê‰∏¥Êó∂Êñá‰ª∂ÂêçÔºàÁî®‰∫ékubectl applyÔºâ
    const tempFileName = `torch-training-${trainingJobName}-${timestamp}.yaml`;
    const tempFilePath = path.join(__dirname, '../temp', tempFileName);

    // ÁîüÊàêÊ∞∏‰πÖ‰øùÂ≠òÁöÑÊñá‰ª∂ÂêçÔºà‰øùÂ≠òÂà∞templates/training/ÁõÆÂΩïÔºâ
    const permanentFileName = `torch_${timestamp}.yaml`;
    const permanentFilePath = path.join(__dirname, '../templates/training', permanentFileName);

    // Á°Æ‰øùtempÁõÆÂΩïÂ≠òÂú®
    const tempDir = path.join(__dirname, '../temp');
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }

    // Á°Æ‰øùtemplates/trainingÁõÆÂΩïÂ≠òÂú®
    const trainingTemplateDir = path.join(__dirname, '../templates/training');
    if (!fs.existsSync(trainingTemplateDir)) {
      fs.mkdirSync(trainingTemplateDir, { recursive: true });
    }

    // ÂÜôÂÖ•‰∏¥Êó∂Êñá‰ª∂ÔºàÁî®‰∫ékubectl applyÔºâ
    await fs.writeFile(tempFilePath, newYamlContent);
    console.log(`Torch training YAML written to temp file: ${tempFilePath}`);

    // ÂÜôÂÖ•Ê∞∏‰πÖÊñá‰ª∂Ôºà‰øùÂ≠òÂà∞templates/training/ÁõÆÂΩïÔºâ
    await fs.writeFile(permanentFilePath, newYamlContent);
    console.log(`Torch training YAML saved permanently to: ${permanentFilePath}`);

    // Â∫îÁî®YAMLÈÖçÁΩÆ - ËÆ≠ÁªÉ‰ªªÂä°ÂèØËÉΩÈúÄË¶ÅÊõ¥ÈïøÊó∂Èó¥
    const applyOutput = await executeKubectl(`apply -f ${tempFilePath}`, 60000); // 60ÁßíË∂ÖÊó∂
    console.log('Torch training job apply output:', applyOutput);

    // Ê∏ÖÁêÜ‰∏¥Êó∂Êñá‰ª∂
    try {
      await fs.unlink(tempFilePath);
      console.log(`Temporary file deleted: ${tempFilePath}`);
    } catch (cleanupError) {
      console.warn(`Failed to delete temporary file: ${cleanupError.message}`);
    }

    // ÂπøÊí≠ËÆ≠ÁªÉ‰ªªÂä°ÂêØÂä®Áä∂ÊÄÅÊõ¥Êñ∞
    broadcast({
      type: 'training_launch',
      status: 'success',
      message: `Successfully launched torch training job: ${trainingJobName}`,
      output: applyOutput
    });

    res.json({
      success: true,
      message: `Torch training job "${trainingJobName}" launched successfully`,
      trainingJobName: trainingJobName,
      savedTemplate: permanentFileName,
      savedTemplatePath: permanentFilePath,
      output: applyOutput
    });

  } catch (error) {
    console.error('Torch training launch error details:', {
      message: error.message,
      stack: error.stack,
      error: error
    });
    
    const errorMessage = error.message || error.toString() || 'Unknown error occurred';
    
    broadcast({
      type: 'training_launch',
      status: 'error',
      message: `Torch training launch failed: ${errorMessage}`
    });
    
    res.status(500).json({
      success: false,
      error: errorMessage
    });
  }
});

// ÁîüÊàêÂπ∂ÈÉ®ÁΩ≤HyperPodËÆ≠ÁªÉ‰ªªÂä° - ‰∏ìÈó®Áî®‰∫éLlamaFactoryËÆ≠ÁªÉ‰ªªÂä°
app.post('/api/launch-training', async (req, res) => {
  try {
    console.log('Raw request body:', JSON.stringify(req.body, null, 2));
    
    const {
      trainingJobName,
      dockerImage = 'pytorch/pytorch:latest',
      instanceType = 'ml.g5.12xlarge',
      nprocPerNode = 1,
      replicas = 1,
      efaCount = 0,
      lmfRecipeRunPath,
      lmfRecipeYamlFile,
      mlflowTrackingUri = '',
      logMonitoringConfig
    } = req.body;

    console.log('Training launch request parsed:', { 
      trainingJobName,
      dockerImage,
      instanceType,
      nprocPerNode,
      replicas,
      efaCount,
      lmfRecipeRunPath,
      lmfRecipeYamlFile,
      mlflowTrackingUri,
      logMonitoringConfig: logMonitoringConfig ? 'present' : 'empty'
    });

    // È™åËØÅÂøÖÈúÄÂèÇÊï∞
    if (!trainingJobName) {
      return res.status(400).json({
        success: false,
        error: 'Training job name is required'
      });
    }

    if (!lmfRecipeRunPath) {
      return res.status(400).json({
        success: false,
        error: 'LlamaFactory Recipe Run Path is required'
      });
    }

    if (!lmfRecipeYamlFile) {
      return res.status(400).json({
        success: false,
        error: 'LlamaFactory Config YAML File Name is required'
      });
    }

    // ËØªÂèñËÆ≠ÁªÉ‰ªªÂä°Ê®°Êùø
    const templatePath = path.join(__dirname, '../templates/hyperpod-training-lmf-template.yaml');
    const templateContent = await fs.readFile(templatePath, 'utf8');
    
    // Â§ÑÁêÜÊó•ÂøóÁõëÊéßÈÖçÁΩÆ
    let logMonitoringConfigYaml = '';
    if (logMonitoringConfig && logMonitoringConfig.trim() !== '') {
      // Ê∑ªÂä†ÈÄÇÂΩìÁöÑÁº©Ëøõ
      const indentedConfig = logMonitoringConfig
        .split('\n')
        .map(line => line.trim() ? `    ${line}` : line)
        .join('\n');
      logMonitoringConfigYaml = `
    logMonitoringConfiguration: 
${indentedConfig}`;
    }
    
    // ÊõøÊç¢Ê®°Êùø‰∏≠ÁöÑÂç†‰ΩçÁ¨¶
    const newYamlContent = templateContent
      .replace(/TRAINING_JOB_NAME/g, trainingJobName)
      .replace(/DOCKER_IMAGE/g, dockerImage)
      .replace(/INSTANCE_TYPE/g, instanceType)
      .replace(/NPROC_PER_NODE/g, nprocPerNode.toString())
      .replace(/REPLICAS_COUNT/g, replicas.toString())
      .replace(/EFA_PER_NODE/g, efaCount.toString())
      .replace(/LMF_RECIPE_RUNPATH_PH/g, lmfRecipeRunPath)
      .replace(/LMF_RECIPE_YAMLFILE_PH/g, lmfRecipeYamlFile)
      .replace(/SM_MLFLOW_ARN/g, mlflowTrackingUri)
      .replace(/LOG_MONITORING_CONFIG/g, logMonitoringConfigYaml);

    console.log('Generated training YAML content:', newYamlContent);

    // ÁîüÊàêÊó∂Èó¥Êà≥
    const timestamp = Date.now();
    
    // ÁîüÊàê‰∏¥Êó∂Êñá‰ª∂ÂêçÔºàÁî®‰∫ékubectl applyÔºâ
    const tempFileName = `training-${trainingJobName}-${timestamp}.yaml`;
    const tempFilePath = path.join(__dirname, '../temp', tempFileName);

    // ÁîüÊàêÊ∞∏‰πÖ‰øùÂ≠òÁöÑÊñá‰ª∂ÂêçÔºà‰øùÂ≠òÂà∞templates/training/ÁõÆÂΩïÔºâ
    const permanentFileName = `lma_${timestamp}.yaml`;
    const permanentFilePath = path.join(__dirname, '../templates/training', permanentFileName);

    // Á°Æ‰øùtempÁõÆÂΩïÂ≠òÂú®
    const tempDir = path.join(__dirname, '../temp');
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }

    // Á°Æ‰øùtemplates/trainingÁõÆÂΩïÂ≠òÂú®
    const trainingTemplateDir = path.join(__dirname, '../templates/training');
    if (!fs.existsSync(trainingTemplateDir)) {
      fs.mkdirSync(trainingTemplateDir, { recursive: true });
    }

    // ÂÜôÂÖ•‰∏¥Êó∂Êñá‰ª∂ÔºàÁî®‰∫ékubectl applyÔºâ
    await fs.writeFile(tempFilePath, newYamlContent);
    console.log(`Training YAML written to temp file: ${tempFilePath}`);

    // ÂÜôÂÖ•Ê∞∏‰πÖÊñá‰ª∂Ôºà‰øùÂ≠òÂà∞templates/training/ÁõÆÂΩïÔºâ
    await fs.writeFile(permanentFilePath, newYamlContent);
    console.log(`Training YAML saved permanently to: ${permanentFilePath}`);

    // Â∫îÁî®YAMLÈÖçÁΩÆ - ËÆ≠ÁªÉ‰ªªÂä°ÂèØËÉΩÈúÄË¶ÅÊõ¥ÈïøÊó∂Èó¥
    const applyOutput = await executeKubectl(`apply -f ${tempFilePath}`, 60000); // 60ÁßíË∂ÖÊó∂
    console.log('Training job apply output:', applyOutput);

    // Ê∏ÖÁêÜ‰∏¥Êó∂Êñá‰ª∂
    try {
      await fs.unlink(tempFilePath);
      console.log(`Temporary file deleted: ${tempFilePath}`);
    } catch (cleanupError) {
      console.warn(`Failed to delete temporary file: ${cleanupError.message}`);
    }

    // ÂπøÊí≠ËÆ≠ÁªÉ‰ªªÂä°ÂêØÂä®Áä∂ÊÄÅÊõ¥Êñ∞
    broadcast({
      type: 'training_launch',
      status: 'success',
      message: `Successfully launched training job: ${trainingJobName}`,
      output: applyOutput
    });

    res.json({
      success: true,
      message: `Training job "${trainingJobName}" launched successfully`,
      trainingJobName: trainingJobName,
      savedTemplate: permanentFileName,
      savedTemplatePath: permanentFilePath,
      output: applyOutput
    });

  } catch (error) {
    console.error('Training launch error details:', {
      message: error.message,
      stack: error.stack,
      error: error
    });
    
    const errorMessage = error.message || error.toString() || 'Unknown error occurred';
    
    broadcast({
      type: 'training_launch',
      status: 'error',
      message: `Training launch failed: ${errorMessage}`
    });
    
    res.status(500).json({
      success: false,
      error: errorMessage
    });
  }
});

// ‰øùÂ≠òLlamaFactoryÈÖçÁΩÆ
app.post('/api/llamafactory-config/save', async (req, res) => {
  try {
    const config = req.body;
    const configPath = path.join(__dirname, '../config/llamafactory-config.json');
    
    // Á°Æ‰øùconfigÁõÆÂΩïÂ≠òÂú®
    const configDir = path.join(__dirname, '../config');
    if (!fs.existsSync(configDir)) {
      fs.mkdirSync(configDir, { recursive: true });
    }
    
    await fs.writeFile(configPath, JSON.stringify(config, null, 2));
    console.log('LlamaFactory config saved:', config);
    
    res.json({
      success: true,
      message: 'LlamaFactory configuration saved successfully'
    });
  } catch (error) {
    console.error('Error saving training config:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// Âä†ËΩΩLlamaFactoryÈÖçÁΩÆ
app.get('/api/llamafactory-config/load', async (req, res) => {
  try {
    const configPath = path.join(__dirname, '../config/llamafactory-config.json');
    
    if (!fs.existsSync(configPath)) {
      // ËøîÂõûÈªòËÆ§ÈÖçÁΩÆ
      const defaultConfig = {
        trainingJobName: 'lmf-v1',
        dockerImage: '633205212955.dkr.ecr.us-west-2.amazonaws.com/sm-training-op-torch26-smhp-op-v2:latest',
        instanceType: 'ml.g6.12xlarge',
        nprocPerNode: 4,
        replicas: 1,
        efaCount: 1,
        lmfRecipeRunPath: '/s3/train-recipes/llama-factory-project/',
        lmfRecipeYamlFile: 'qwen_full_dist_template.yaml',
        mlflowTrackingUri: '',
        logMonitoringConfig: ''
      };
      
      return res.json({
        success: true,
        config: defaultConfig,
        isDefault: true
      });
    }
    
    const configContent = await fs.readFile(configPath, 'utf8');
    const config = JSON.parse(configContent);
    
    console.log('LlamaFactory config loaded:', config);
    
    res.json({
      success: true,
      config: config,
      isDefault: false
    });
  } catch (error) {
    console.error('Error loading training config:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// ‰øùÂ≠òScriptÈÖçÁΩÆ
app.post('/api/script-config/save', async (req, res) => {
  try {
    const config = req.body;
    const configPath = path.join(__dirname, '../config/script-config.json');
    
    // Á°Æ‰øùconfigÁõÆÂΩïÂ≠òÂú®
    const configDir = path.join(__dirname, '../config');
    if (!fs.existsSync(configDir)) {
      fs.mkdirSync(configDir, { recursive: true });
    }
    
    await fs.writeFile(configPath, JSON.stringify(config, null, 2));
    console.log('Script config saved:', config);
    
    res.json({
      success: true,
      message: 'Script configuration saved successfully'
    });
  } catch (error) {
    console.error('Error saving script config:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// Âä†ËΩΩScriptÈÖçÁΩÆ
app.get('/api/script-config/load', async (req, res) => {
  try {
    const configPath = path.join(__dirname, '../config/script-config.json');
    
    if (!fs.existsSync(configPath)) {
      // ËøîÂõûÈªòËÆ§ÈÖçÁΩÆ
      const defaultConfig = {
        trainingJobName: 'hypd-recipe-script-1',
        dockerImage: '633205212955.dkr.ecr.us-west-2.amazonaws.com/sm-training-op-torch26-smhp-op:latest',
        instanceType: 'ml.g5.12xlarge',
        nprocPerNode: 1,
        replicas: 1,
        efaCount: 16,
        projectPath: '/s3/training_code/my-training-project/',
        entryPath: 'train.py',
        mlflowTrackingUri: '',
        logMonitoringConfig: ''
      };
      
      return res.json({
        success: true,
        config: defaultConfig,
        isDefault: true
      });
    }
    
    const configContent = await fs.readFile(configPath, 'utf8');
    const config = JSON.parse(configContent);
    
    console.log('Script config loaded:', config);
    
    res.json({
      success: true,
      config: config,
      isDefault: false
    });
  } catch (error) {
    console.error('Error loading script config:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// ÁîüÊàêÂπ∂ÈÉ®ÁΩ≤HyperPod ScriptËÆ≠ÁªÉ‰ªªÂä° - ‰∏ìÈó®Áî®‰∫éScriptËÆ≠ÁªÉ
app.post('/api/launch-script-training', async (req, res) => {
  try {
    console.log('Raw script training request body:', JSON.stringify(req.body, null, 2));
    
    const {
      trainingJobName,
      dockerImage = '633205212955.dkr.ecr.us-west-2.amazonaws.com/sm-training-op-torch26-smhp-op:latest',
      instanceType = 'ml.g5.12xlarge',
      nprocPerNode = 1,
      replicas = 1,
      efaCount = 16,
      projectPath,
      entryPath,
      mlflowTrackingUri = '',
      logMonitoringConfig
    } = req.body;

    console.log('Script training launch request parsed:', { 
      trainingJobName,
      dockerImage,
      instanceType,
      nprocPerNode,
      replicas,
      efaCount,
      projectPath,
      entryPath,
      mlflowTrackingUri,
      logMonitoringConfig: logMonitoringConfig ? 'present' : 'empty'
    });

    // È™åËØÅÂøÖÈúÄÂèÇÊï∞
    if (!trainingJobName) {
      return res.status(400).json({
        success: false,
        error: 'Training job name is required'
      });
    }

    if (!projectPath) {
      return res.status(400).json({
        success: false,
        error: 'Project Path is required'
      });
    }

    if (!entryPath) {
      return res.status(400).json({
        success: false,
        error: 'Entry Script Path is required'
      });
    }

    // ËØªÂèñScriptËÆ≠ÁªÉ‰ªªÂä°Ê®°Êùø
    const templatePath = path.join(__dirname, '../templates/hyperpod-training-script-template.yaml');
    const templateContent = await fs.readFile(templatePath, 'utf8');
    
    // Â§ÑÁêÜÊó•ÂøóÁõëÊéßÈÖçÁΩÆ
    let logMonitoringConfigYaml = '';
    if (logMonitoringConfig && logMonitoringConfig.trim() !== '') {
      // Ê∑ªÂä†ÈÄÇÂΩìÁöÑÁº©Ëøõ
      const indentedConfig = logMonitoringConfig
        .split('\n')
        .map(line => line.trim() ? `    ${line}` : line)
        .join('\n');
      logMonitoringConfigYaml = `
    logMonitoringConfiguration: 
${indentedConfig}`;
    }
    
    // ÊõøÊç¢Ê®°Êùø‰∏≠ÁöÑÂç†‰ΩçÁ¨¶
    const newYamlContent = templateContent
      .replace(/TRAINING_JOB_NAME/g, trainingJobName)
      .replace(/DOCKER_IMAGE/g, dockerImage)
      .replace(/INSTANCE_TYPE/g, instanceType)
      .replace(/NPROC_PER_NODE/g, nprocPerNode.toString())
      .replace(/REPLICAS_COUNT/g, replicas.toString())
      .replace(/EFA_PER_NODE/g, efaCount.toString())
      .replace(/SCRIPT_RECIPE_PROJECTPATH_PH/g, projectPath)
      .replace(/SCRIPT_RECIPE_ENTRYPATH_PH/g, entryPath)
      .replace(/SM_MLFLOW_ARN/g, mlflowTrackingUri)
      .replace(/LOG_MONITORING_CONFIG/g, logMonitoringConfigYaml);

    console.log('Generated script training YAML content:', newYamlContent);

    // ÁîüÊàêÊó∂Èó¥Êà≥
    const timestamp = Date.now();
    
    // ÁîüÊàê‰∏¥Êó∂Êñá‰ª∂ÂêçÔºàÁî®‰∫ékubectl applyÔºâ
    const tempFileName = `script-training-${trainingJobName}-${timestamp}.yaml`;
    const tempFilePath = path.join(__dirname, '../temp', tempFileName);

    // ÁîüÊàêÊ∞∏‰πÖ‰øùÂ≠òÁöÑÊñá‰ª∂ÂêçÔºà‰øùÂ≠òÂà∞templates/training/ÁõÆÂΩïÔºâ
    const permanentFileName = `script_${timestamp}.yaml`;
    const permanentFilePath = path.join(__dirname, '../templates/training', permanentFileName);

    // Á°Æ‰øùtempÁõÆÂΩïÂ≠òÂú®
    const tempDir = path.join(__dirname, '../temp');
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }

    // Á°Æ‰øùtemplates/trainingÁõÆÂΩïÂ≠òÂú®
    const trainingTemplateDir = path.join(__dirname, '../templates/training');
    if (!fs.existsSync(trainingTemplateDir)) {
      fs.mkdirSync(trainingTemplateDir, { recursive: true });
    }

    // ÂÜôÂÖ•‰∏¥Êó∂Êñá‰ª∂ÔºàÁî®‰∫ékubectl applyÔºâ
    await fs.writeFile(tempFilePath, newYamlContent);
    console.log(`Script training YAML written to temp file: ${tempFilePath}`);

    // ÂÜôÂÖ•Ê∞∏‰πÖÊñá‰ª∂Ôºà‰øùÂ≠òÂà∞templates/training/ÁõÆÂΩïÔºâ
    await fs.writeFile(permanentFilePath, newYamlContent);
    console.log(`Script training YAML saved permanently to: ${permanentFilePath}`);

    // Â∫îÁî®YAMLÈÖçÁΩÆ - ËÆ≠ÁªÉ‰ªªÂä°ÂèØËÉΩÈúÄË¶ÅÊõ¥ÈïøÊó∂Èó¥
    const applyOutput = await executeKubectl(`apply -f ${tempFilePath}`, 60000); // 60ÁßíË∂ÖÊó∂
    console.log('Script training job apply output:', applyOutput);

    // Ê∏ÖÁêÜ‰∏¥Êó∂Êñá‰ª∂
    try {
      await fs.unlink(tempFilePath);
      console.log(`Temporary file deleted: ${tempFilePath}`);
    } catch (cleanupError) {
      console.warn(`Failed to delete temporary file: ${cleanupError.message}`);
    }

    // ÂπøÊí≠ËÆ≠ÁªÉ‰ªªÂä°ÂêØÂä®Áä∂ÊÄÅÊõ¥Êñ∞
    broadcast({
      type: 'training_launch',
      status: 'success',
      message: `Successfully launched script training job: ${trainingJobName}`,
      output: applyOutput
    });

    res.json({
      success: true,
      message: `Script training job "${trainingJobName}" launched successfully`,
      trainingJobName: trainingJobName,
      savedTemplate: permanentFileName,
      savedTemplatePath: permanentFilePath,
      output: applyOutput
    });

  } catch (error) {
    console.error('Script training launch error details:', {
      message: error.message,
      stack: error.stack,
      error: error
    });
    
    const errorMessage = error.message || error.toString() || 'Unknown error occurred';
    
    broadcast({
      type: 'training_launch',
      status: 'error',
      message: `Script training launch failed: ${errorMessage}`
    });
    
    res.status(500).json({
      success: false,
      error: errorMessage
    });
  }
});

// ‰øùÂ≠òTorchÈÖçÁΩÆ
app.post('/api/torch-config/save', async (req, res) => {
  try {
    const config = req.body;
    const configPath = path.join(__dirname, '../config/torch-config.json');
    
    // Á°Æ‰øùconfigÁõÆÂΩïÂ≠òÂú®
    const configDir = path.join(__dirname, '../config');
    if (!fs.existsSync(configDir)) {
      fs.mkdirSync(configDir, { recursive: true });
    }
    
    await fs.writeFile(configPath, JSON.stringify(config, null, 2));
    console.log('Torch config saved:', config);
    
    res.json({
      success: true,
      message: 'Torch configuration saved successfully'
    });
  } catch (error) {
    console.error('Error saving torch config:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// Âä†ËΩΩTorchÈÖçÁΩÆ
app.get('/api/torch-config/load', async (req, res) => {
  try {
    const configPath = path.join(__dirname, '../config/torch-config.json');
    
    if (!fs.existsSync(configPath)) {
      // ËøîÂõûÈªòËÆ§ÈÖçÁΩÆ
      const defaultConfig = {
        trainingJobName: 'hypd-recipe-torch-1',
        dockerImage: '633205212955.dkr.ecr.us-west-2.amazonaws.com/sm-training-op-torch26-smhp-op:latest',
        instanceType: 'ml.g5.12xlarge',
        nprocPerNode: 1,
        replicas: 1,
        efaCount: 16,
        entryPythonScriptPath: '/s3/training_code/model-training-with-hyperpod-training-operator/torch-training.py',
        pythonScriptParameters: '--learning_rate 1e-5 \\\n--batch_size 1',
        mlflowTrackingUri: '',
        logMonitoringConfig: ''
      };
      
      return res.json({
        success: true,
        config: defaultConfig,
        isDefault: true
      });
    }
    
    const configContent = await fs.readFile(configPath, 'utf8');
    const config = JSON.parse(configContent);
    
    console.log('Torch config loaded:', config);
    
    res.json({
      success: true,
      config: config,
      isDefault: false
    });
  } catch (error) {
    console.error('Error loading torch config:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// ‰øùÂ≠òverlÈÖçÁΩÆ
app.post('/api/verl-config/save', async (req, res) => {
  try {
    const config = req.body;
    const configPath = path.join(__dirname, '../config/verl-config.json');
    
    // Á°Æ‰øùconfigÁõÆÂΩïÂ≠òÂú®
    const configDir = path.join(__dirname, '../config');
    if (!fs.existsSync(configDir)) {
      fs.mkdirSync(configDir, { recursive: true });
    }
    
    await fs.writeFile(configPath, JSON.stringify(config, null, 2));
    console.log('VERL config saved:', config);
    
    res.json({
      success: true,
      message: 'VERL configuration saved successfully'
    });
  } catch (error) {
    console.error('Error saving VERL config:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// Âä†ËΩΩverlÈÖçÁΩÆ
app.get('/api/verl-config/load', async (req, res) => {
  try {
    const configPath = path.join(__dirname, '../config/verl-config.json');
    
    if (!fs.existsSync(configPath)) {
      // ËøîÂõûÈªòËÆ§ÈÖçÁΩÆ
      const defaultConfig = {
        jobName: 'verl-training-a1',
        instanceType: 'ml.g5.12xlarge',
        entryPointPath: 'verl-project/src/qwen-3b-grpo-kuberay.sh',
        dockerImage: '633205212955.dkr.ecr.us-west-2.amazonaws.com/hypd-verl:latest',
        workerReplicas: 1,
        gpuPerNode: 4,
        efaPerNode: 1
      };
      
      return res.json({
        success: true,
        config: defaultConfig,
        isDefault: true
      });
    }
    
    const configContent = await fs.readFile(configPath, 'utf8');
    const config = JSON.parse(configContent);
    
    console.log('VERL config loaded:', config);
    
    res.json({
      success: true,
      config: config,
      isDefault: false
    });
  } catch (error) {
    console.error('Error loading VERL config:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// ÁîüÊàêÂπ∂ÈÉ®ÁΩ≤VERLËÆ≠ÁªÉ‰ªªÂä° - ‰∏ìÈó®Áî®‰∫éVERLËÆ≠ÁªÉ
app.post('/api/launch-verl-training', async (req, res) => {
  try {
    console.log('Raw VERL training request body:', JSON.stringify(req.body, null, 2));
    
    const {
      jobName,
      instanceType = 'ml.g5.12xlarge',
      entryPointPath,
      dockerImage,
      workerReplicas = 1,
      gpuPerNode = 4,
      efaPerNode = 1,
      recipeType
    } = req.body;

    console.log('VERL training launch request parsed:', { 
      jobName,
      instanceType,
      entryPointPath,
      dockerImage,
      workerReplicas,
      gpuPerNode,
      efaPerNode,
      recipeType
    });

    // È™åËØÅÂøÖÈúÄÂèÇÊï∞
    if (!jobName) {
      return res.status(400).json({
        success: false,
        error: 'Job name is required'
      });
    }

    if (!entryPointPath) {
      return res.status(400).json({
        success: false,
        error: 'Entry point path is required'
      });
    }

    if (!dockerImage) {
      return res.status(400).json({
        success: false,
        error: 'Docker image is required'
      });
    }

    // ËØªÂèñVERLËÆ≠ÁªÉ‰ªªÂä°Ê®°Êùø
    const templatePath = path.join(__dirname, '../templates/verl-training-template.yaml');
    const templateContent = await fs.readFile(templatePath, 'utf8');
    
    // ÊõøÊç¢Ê®°Êùø‰∏≠ÁöÑÂç†‰ΩçÁ¨¶
    const newYamlContent = templateContent
      .replace(/JOB_NAME/g, jobName)
      .replace(/ENTRY_POINT_PATH/g, entryPointPath)
      .replace(/DOCKER_IMAGE/g, dockerImage)
      .replace(/WORKER_REPLICAS/g, workerReplicas.toString())
      .replace(/MAX_REPLICAS/g, Math.max(3, workerReplicas + 2).toString())
      .replace(/GPU_PER_NODE/g, gpuPerNode.toString())
      .replace(/EFA_PER_NODE/g, efaPerNode.toString());

    console.log('Generated VERL YAML content preview:', newYamlContent.substring(0, 500) + '...');

    // ‰ΩøÁî®Áªü‰∏ÄÁöÑÈÉ®ÁΩ≤ÂáΩÊï∞
    const deployResult = await deployTrainingYaml('verl', jobName, newYamlContent);

    res.json({
      success: true,
      message: `VERL training job "${jobName}" launched successfully`,
      jobName: jobName,
      templateUsed: 'verl-training-template.yaml',
      savedTemplate: deployResult.permanentFileName,
      savedTemplatePath: deployResult.permanentFilePath,
      output: deployResult.applyOutput
    });

  } catch (error) {
    console.error('VERL training launch error:', error);
    
    res.status(500).json({
      success: false,
      error: error.message || 'Unknown error occurred'
    });
  }
});

// Ëé∑ÂèñÊâÄÊúâRayJob
app.get('/api/rayjobs', async (req, res) => {
  try {
    const output = await executeKubectl('get rayjobs -o json');
    const rayjobs = JSON.parse(output);
    res.json(rayjobs.items);
  } catch (error) {
    console.error('RayJobs fetch error:', error);
    res.status(500).json({ error: error.message });
  }
});

// Âà†Èô§ÊåáÂÆöÁöÑRayJob
app.delete('/api/rayjobs/:jobName', async (req, res) => {
  try {
    const { jobName } = req.params;
    console.log(`Deleting RayJob: ${jobName}`);
    
    const output = await executeKubectl(`delete rayjob ${jobName}`);
    console.log('RayJob delete output:', output);
    
    // ÂèëÈÄÅWebSocketÂπøÊí≠
    broadcast({
      type: 'rayjob_deleted',
      status: 'success',
      message: `RayJob "${jobName}" deleted successfully`,
      jobName: jobName
    });
    
    res.json({
      success: true,
      message: `RayJob "${jobName}" deleted successfully`,
      output: output
    });
  } catch (error) {
    console.error('Error deleting RayJob:', error);
    
    broadcast({
      type: 'rayjob_deleted',
      status: 'error',
      message: `Failed to delete RayJob: ${error.message}`
    });
    
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// Ëé∑ÂèñÊâÄÊúâHyperPodËÆ≠ÁªÉ‰ªªÂä°
app.get('/api/training-jobs', async (req, res) => {
  try {
    console.log('Fetching training jobs (HyperPod PytorchJob + RayJob)...');
    
    // Ëé∑ÂèñHyperPod PytorchJob
    let hyperpodJobs = [];
    try {
      const hyperpodOutput = await executeKubectl('get hyperpodpytorchjob -o json');
      const hyperpodResult = JSON.parse(hyperpodOutput);
      hyperpodJobs = hyperpodResult.items.map(job => ({
        name: job.metadata.name,
        namespace: job.metadata.namespace || 'default',
        creationTimestamp: job.metadata.creationTimestamp,
        status: job.status || {},
        type: 'hyperpod',
        spec: {
          replicas: job.spec?.replicaSpecs?.[0]?.replicas || 0,
          nprocPerNode: job.spec?.nprocPerNode || 0
        }
      }));
    } catch (error) {
      const optimizedMessage = optimizeErrorMessage(error.message);
      console.log('No HyperPod PytorchJobs found or error:', optimizedMessage);
      // ÂØπ‰∫éÂØºÂÖ•ÁöÑÈõÜÁæ§ÔºåËøôÊòØÊ≠£Â∏∏ÁöÑ - ‰∏çËÆ∞ÂΩï‰∏∫ÈîôËØØ
    }

    // Ëé∑ÂèñRayJob
    let rayJobs = [];
    try {
      const rayOutput = await executeKubectl('get rayjob -o json');
      const rayResult = JSON.parse(rayOutput);
      rayJobs = rayResult.items.map(job => ({
        name: job.metadata.name,
        namespace: job.metadata.namespace || 'default',
        creationTimestamp: job.metadata.creationTimestamp,
        status: job.status || {},
        type: 'rayjob',
        spec: {
          replicas: 1, // RayJobÈÄöÂ∏∏ÊòØÂçï‰∏™‰Ωú‰∏ö
          nprocPerNode: 1
        }
      }));
    } catch (error) {
      const optimizedMessage = optimizeErrorMessage(error.message);
      console.log('No RayJobs found or error:', optimizedMessage);
      // ÂØπ‰∫éÂØºÂÖ•ÁöÑÈõÜÁæ§ÔºåËøôÊòØÊ≠£Â∏∏ÁöÑ - ‰∏çËÆ∞ÂΩï‰∏∫ÈîôËØØ
    }

    // ÂêàÂπ∂‰∏§ÁßçÁ±ªÂûãÁöÑ‰Ωú‰∏ö
    const trainingJobs = [...hyperpodJobs, ...rayJobs];
    
    console.log(`Found ${trainingJobs.length} training jobs (${hyperpodJobs.length} HyperPod + ${rayJobs.length} Ray):`, 
                trainingJobs.map(j => `${j.name}(${j.type})`));
    
    res.json({
      success: true,
      jobs: trainingJobs
    });
  } catch (error) {
    console.error('Error fetching training jobs:', error);
    res.status(500).json({
      success: false,
      error: error.message,
      jobs: []
    });
  }
});

// Âà†Èô§ÊåáÂÆöÁöÑHyperPodËÆ≠ÁªÉ‰ªªÂä°
app.delete('/api/training-jobs/:jobName', async (req, res) => {
  try {
    const { jobName } = req.params;
    console.log(`Deleting training job: ${jobName}`);
    
    const output = await executeKubectl(`delete hyperpodpytorchjob ${jobName}`);
    console.log('Delete output:', output);
    
    // ÂπøÊí≠Âà†Èô§Áä∂ÊÄÅÊõ¥Êñ∞
    broadcast({
      type: 'training_job_deleted',
      status: 'success',
      message: `Training job "${jobName}" deleted successfully`,
      jobName: jobName
    });
    
    res.json({
      success: true,
      message: `Training job "${jobName}" deleted successfully`,
      output: output
    });
  } catch (error) {
    console.error('Error deleting training job:', error);
    
    broadcast({
      type: 'training_job_deleted',
      status: 'error',
      message: `Failed to delete training job: ${error.message}`
    });
    
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// MLflowÈÖçÁΩÆÁÆ°ÁêÜ

const CONFIG_FILE = path.join(__dirname, '../config/mlflow-metric-config.json');

// Á°Æ‰øùÈÖçÁΩÆÁõÆÂΩïÂ≠òÂú®
const configDir = path.dirname(CONFIG_FILE);
if (!fs.existsSync(configDir)) {
  fs.mkdirSync(configDir, { recursive: true });
}

// ÈªòËÆ§MLflowÈÖçÁΩÆ
const DEFAULT_MLFLOW_CONFIG = {
  tracking_uri: '',
  experiment_id: '',
  sync_configs: {}
};

// ËØªÂèñMLflowÈÖçÁΩÆ
function readMlflowConfig() {
  try {
    if (fs.existsSync(CONFIG_FILE)) {
      const configData = fs.readFileSync(CONFIG_FILE, 'utf8');
      return JSON.parse(configData);
    }
  } catch (error) {
    console.error('Error reading MLflow config:', error);
  }
  return DEFAULT_MLFLOW_CONFIG;
}

// ‰øùÂ≠òMLflowÈÖçÁΩÆ
function saveMlflowConfig(config) {
  try {
    fs.writeFileSync(CONFIG_FILE, JSON.stringify(config, null, 2));
    return true;
  } catch (error) {
    console.error('Error saving MLflow config:', error);
    return false;
  }
}

// Ëé∑ÂèñMLflowÈÖçÁΩÆ
app.get('/api/mlflow-metric-config', (req, res) => {
  try {
    const config = readMlflowConfig();
    res.json({
      success: true,
      config: config
    });
  } catch (error) {
    console.error('Error fetching MLflow config:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// ‰øùÂ≠òMLflowÈÖçÁΩÆ
app.post('/api/mlflow-metric-config', (req, res) => {
  try {
    const { tracking_uri } = req.body;
    
    if (!tracking_uri) {
      return res.status(400).json({
        success: false,
        error: 'tracking_uri is required'
      });
    }

    const config = { tracking_uri };
    
    if (saveMlflowConfig(config)) {
      console.log('MLflow config saved:', config);
      res.json({
        success: true,
        config: config
      });
    } else {
      res.status(500).json({
        success: false,
        error: 'Failed to save configuration'
      });
    }
  } catch (error) {
    console.error('Error saving MLflow config:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// ÊµãËØïMLflowËøûÊé•
app.post('/api/mlflow-metric-config/test', async (req, res) => {
  try {
    const { tracking_uri } = req.body;
    
    if (!tracking_uri) {
      return res.status(400).json({
        success: false,
        error: 'tracking_uri is required'
      });
    }

    console.log(`Testing MLflow connection to: ${tracking_uri}`);
    
    const { spawn } = require('child_process');
    
    // ÂàõÂª∫ÊµãËØïËÑöÊú¨
    const testScript = `#!/usr/bin/env python3
import mlflow
import sys
import json

try:
    tracking_uri = "${tracking_uri}"
    mlflow.set_tracking_uri(tracking_uri)
    
    # Â∞ùËØïËé∑ÂèñÂÆûÈ™åÂàóË°®Êù•ÊµãËØïËøûÊé•
    experiments = mlflow.search_experiments()
    
    result = {
        "success": True,
        "experiments_count": len(experiments),
        "message": f"Successfully connected to MLflow. Found {len(experiments)} experiments."
    }
    
    print(json.dumps(result))
    sys.exit(0)
    
except Exception as e:
    result = {
        "success": False,
        "error": str(e)
    }
    print(json.dumps(result))
    sys.exit(1)
`;
    
    const tempScriptPath = path.join(__dirname, '../temp/test_mlflow_connection.py');
    
    // Á°Æ‰øùtempÁõÆÂΩïÂ≠òÂú®
    const tempDir = path.dirname(tempScriptPath);
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }
    
    fs.writeFileSync(tempScriptPath, testScript);
    
    const pythonPath = 'python3'; // ‰ΩøÁî®Á≥ªÁªüPython
    const pythonProcess = spawn(pythonPath, [tempScriptPath], {
      cwd: __dirname,
      env: { ...process.env }
    });
    
    let stdout = '';
    let stderr = '';
    
    pythonProcess.stdout.on('data', (data) => {
      stdout += data.toString();
    });
    
    pythonProcess.stderr.on('data', (data) => {
      stderr += data.toString();
    });
    
    pythonProcess.on('close', (code) => {
      // Ê∏ÖÁêÜ‰∏¥Êó∂Êñá‰ª∂
      try {
        fs.unlinkSync(tempScriptPath);
      } catch (e) {
        console.warn('Failed to cleanup temp file:', e);
      }
      
      if (stderr) {
        console.log('Python test script stderr:', stderr);
      }
      
      try {
        const result = JSON.parse(stdout);
        if (result.success) {
          res.json(result);
        } else {
          res.status(400).json(result);
        }
      } catch (parseError) {
        console.error('Failed to parse test result:', parseError);
        console.error('Raw output:', stdout);
        res.status(500).json({
          success: false,
          error: 'Failed to test MLflow connection',
          details: stdout || stderr
        });
      }
    });
    
    pythonProcess.on('error', (error) => {
      console.error('Failed to start Python test script:', error);
      res.status(500).json({
        success: false,
        error: `Failed to start test script: ${error.message}`
      });
    });
    
  } catch (error) {
    console.error('MLflow connection test error:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// MLflowË∑®Ë¥¶Êà∑ÂêåÊ≠•API
app.post('/api/mlflow-sync', async (req, res) => {
  try {
    const { sync_config, experiment_name, experiment_id } = req.body;
    
    // ÊîØÊåÅ‰∏§ÁßçÂèÇÊï∞Ê†ºÂºè‰ª•‰øùÊåÅÂÖºÂÆπÊÄß
    const experimentIdentifier = experiment_name || experiment_id;
    
    // È™åËØÅÂøÖÈúÄÂ≠óÊÆµ
    if (!sync_config || !experimentIdentifier) {
      return res.status(400).json({
        success: false,
        error: 'sync_config and experiment_name (or experiment_id) are required'
      });
    }

    // È™åËØÅJSONÈÖçÁΩÆ
    let configObj;
    try {
      configObj = JSON.parse(sync_config);
    } catch (e) {
      return res.status(400).json({
        success: false,
        error: 'Invalid JSON format in sync_config'
      });
    }

    // È™åËØÅÂøÖÈúÄÁöÑÈÖçÁΩÆÂ≠óÊÆµ
    const requiredFields = ['contributor_name', 'source_mlflow_arn', 'shared_account_id', 'shared_aws_region', 'cross_account_role_arn', 'shared_mlflow_arn'];
    const missingFields = requiredFields.filter(field => !configObj[field]);
    if (missingFields.length > 0) {
      return res.status(400).json({
        success: false,
        error: `Missing required fields in sync_config: ${missingFields.join(', ')}`
      });
    }

    // È™åËØÅsourceÂíådestination ARN‰∏çËÉΩÁõ∏Âêå
    if (configObj.source_mlflow_arn === configObj.shared_mlflow_arn) {
      return res.status(400).json({
        success: false,
        error: 'Source MLflow ARN and Shared MLflow ARN cannot be the same. Please ensure you are syncing to a different MLflow server.'
      });
    }

    // Ê∑ªÂä†Êó∂Èó¥Êà≥
    configObj.setup_date = new Date().toISOString();

    console.log(`Starting MLflow sync for experiment ${experimentIdentifier}...`);
    
    // 1. ‰øùÂ≠òÈÖçÁΩÆÂà∞mlflow-metric-config.json
    const currentConfig = readMlflowConfig();
    const updatedConfig = {
      ...currentConfig,
      experiment_name: experimentIdentifier,  // Êîπ‰∏∫experiment_name
      sync_configs: {
        ...configObj,
        last_sync: new Date().toISOString()
      }
    };
    
    if (!saveMlflowConfig(updatedConfig)) {
      return res.status(500).json({
        success: false,
        error: 'Failed to save sync configuration'
      });
    }

    // 2. ÂàõÂª∫‰∏¥Êó∂ÈÖçÁΩÆÊñá‰ª∂‰æõPythonËÑöÊú¨‰ΩøÁî®
    const tempConfigPath = path.join(__dirname, '../temp/sync-config-temp.json');
    
    // Á°Æ‰øùtempÁõÆÂΩïÂ≠òÂú®
    const tempDir = path.dirname(tempConfigPath);
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }
    
    fs.writeFileSync(tempConfigPath, JSON.stringify(configObj, null, 2));

    // 3. Ë∞ÉÁî®PythonÂêåÊ≠•ËÑöÊú¨
    const { spawn } = require('child_process');
    const pythonPath = 'python3'; // ‰ΩøÁî®Á≥ªÁªüPython
    const syncScriptPath = path.join(__dirname, '../mlflow/cross_account_sync.py');
    
    const pythonProcess = spawn(pythonPath, [
      syncScriptPath,
      '--config-file', tempConfigPath,
      '--experiment-name', experimentIdentifier
    ], {
      cwd: __dirname,
      env: { ...process.env }
    });
    
    let stdout = '';
    let stderr = '';
    
    pythonProcess.stdout.on('data', (data) => {
      stdout += data.toString();
    });
    
    pythonProcess.stderr.on('data', (data) => {
      stderr += data.toString();
    });
    
    pythonProcess.on('close', (code) => {
      // Ê∏ÖÁêÜ‰∏¥Êó∂ÈÖçÁΩÆÊñá‰ª∂
      try {
        fs.unlinkSync(tempConfigPath);
      } catch (e) {
        console.warn('Failed to cleanup temp config file:', e);
      }
      
      if (code === 0) {
        console.log('MLflow sync completed successfully');
        console.log('Sync output:', stdout);
        
        res.json({
          success: true,
          message: 'Successfully synced experiment to shared MLflow server',
          output: stdout,
          experiment_id: experimentIdentifier,
          contributor: configObj.contributor_name
        });
      } else {
        console.error('MLflow sync failed with code:', code);
        console.error('Sync stderr:', stderr);
        console.error('Sync stdout:', stdout);
        
        res.status(500).json({
          success: false,
          error: 'MLflow sync failed',
          details: stderr || stdout,
          exit_code: code
        });
      }
    });
    
    pythonProcess.on('error', (error) => {
      console.error('Failed to start MLflow sync script:', error);
      
      // Ê∏ÖÁêÜ‰∏¥Êó∂ÈÖçÁΩÆÊñá‰ª∂
      try {
        fs.unlinkSync(tempConfigPath);
      } catch (e) {
        console.warn('Failed to cleanup temp config file:', e);
      }
      
      res.status(500).json({
        success: false,
        error: `Failed to start sync script: ${error.message}`
      });
    });
    
  } catch (error) {
    console.error('MLflow sync API error:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// Ëé∑ÂèñËÆ≠ÁªÉÂéÜÂè≤Êï∞ÊçÆÔºà‰ªéMLflowÔºâ
app.get('/api/training-history', async (req, res) => {
  try {
    console.log('Fetching training history from MLflow...');
    
    // ËØªÂèñÂΩìÂâçMLflowÈÖçÁΩÆ
    const mlflowConfig = readMlflowConfig();
    console.log('Using MLflow URI:', mlflowConfig.tracking_uri);
    
    const { spawn } = require('child_process');
    const path = require('path');
    
    // ‰ΩøÁî®Á≥ªÁªüPythonÊâßË°åËÑöÊú¨Ôºå‰º†ÈÄíÈÖçÁΩÆÂèÇÊï∞
    const pythonPath = 'python3'; // ‰ΩøÁî®Á≥ªÁªüPython
    const scriptPath = path.join(__dirname, '../mlflow/get_training_history.py');
    
    const pythonProcess = spawn(pythonPath, [scriptPath, mlflowConfig.tracking_uri], {
      cwd: __dirname,
      env: { ...process.env }
    });
    
    let stdout = '';
    let stderr = '';
    
    pythonProcess.stdout.on('data', (data) => {
      stdout += data.toString();
    });
    
    pythonProcess.stderr.on('data', (data) => {
      stderr += data.toString();
    });
    
    let responseHandled = false;
    
    pythonProcess.on('close', (code) => {
      if (responseHandled) return;
      
      if (stderr) {
        console.log('Python script stderr:', stderr);
      }
      
      if (code !== 0) {
        console.error(`Python script exited with code ${code}`);
        responseHandled = true;
        return res.status(500).json({ 
          success: false, 
          error: `Failed to fetch training history: exit code ${code}`,
          stderr: stderr
        });
      }
      
      try {
        const result = JSON.parse(stdout);
        console.log(`Training history fetched: ${result.total} records`);
        responseHandled = true;
        res.json(result);
      } catch (parseError) {
        console.error('Failed to parse Python script output:', parseError);
        console.error('Raw output:', stdout);
        responseHandled = true;
        res.status(500).json({ 
          success: false, 
          error: 'Failed to parse training history data',
          raw_output: stdout
        });
      }
    });
    
    pythonProcess.on('error', (error) => {
      if (responseHandled) return;
      
      console.error('Failed to start Python script:', error);
      responseHandled = true;
      res.status(500).json({ 
        success: false, 
        error: `Failed to start Python script: ${error.message}`
      });
    });
    
  } catch (error) {
    console.error('Training history fetch error:', error);
    res.status(500).json({ 
      success: false, 
      error: error.message 
    });
  }
});

// Ëé∑ÂèñËÆ≠ÁªÉ‰ªªÂä°ÂÖ≥ËÅîÁöÑpods
app.get('/api/training-jobs/:jobName/pods', async (req, res) => {
  try {
    const { jobName } = req.params;
    console.log(`Fetching pods for training job: ${jobName}`);
    
    // Ëé∑ÂèñÊâÄÊúâpodsÔºåÁÑ∂ÂêéÁ≠õÈÄâÂá∫Â±û‰∫éËØ•ËÆ≠ÁªÉ‰ªªÂä°ÁöÑpods
    const output = await executeKubectl('get pods -o json');
    const result = JSON.parse(output);
    
    // Á≠õÈÄâÂá∫Â±û‰∫éËØ•ËÆ≠ÁªÉ‰ªªÂä°ÁöÑpods
    const trainingPods = result.items.filter(pod => {
      const labels = pod.metadata.labels || {};
      const ownerReferences = pod.metadata.ownerReferences || [];
      
      // Ê£ÄÊü•ÊòØÂê¶ÈÄöËøáÊ†áÁ≠æÊàñownerReferencesÂÖ≥ËÅîÂà∞ËÆ≠ÁªÉ‰ªªÂä°
      return labels['training-job-name'] === jobName || 
             labels['app'] === jobName ||
             ownerReferences.some(ref => ref.name === jobName) ||
             pod.metadata.name.includes(jobName);
    });
    
    const pods = trainingPods.map(pod => ({
      name: pod.metadata.name,
      namespace: pod.metadata.namespace || 'default',
      status: pod.status.phase,
      creationTimestamp: pod.metadata.creationTimestamp,
      nodeName: pod.spec.nodeName,
      containerStatuses: pod.status.containerStatuses || []
    }));
    
    console.log(`Found ${pods.length} pods for training job ${jobName}:`, pods.map(p => p.name));
    
    res.json({
      success: true,
      pods: pods
    });
  } catch (error) {
    console.error('Error fetching training job pods:', error);
    res.status(500).json({
      success: false,
      error: error.message,
      pods: []
    });
  }
});

// Ëé∑ÂèñÂÆåÊï¥Êó•ÂøóÊñá‰ª∂
app.get('/api/logs/:jobName/:podName', (req, res) => {
  try {
    const { jobName, podName } = req.params;
    const logFilePath = path.join(LOGS_BASE_DIR, jobName, `${podName}.log`);
    
    if (fs.existsSync(logFilePath)) {
      res.sendFile(path.resolve(logFilePath));
    } else {
      res.status(404).json({ 
        success: false, 
        error: 'Log file not found',
        path: logFilePath
      });
    }
  } catch (error) {
    console.error('Error serving log file:', error);
    res.status(500).json({ 
      success: false, 
      error: error.message 
    });
  }
});

// ‰∏ãËΩΩÂÆåÊï¥Êó•ÂøóÊñá‰ª∂
app.get('/api/logs/:jobName/:podName/download', (req, res) => {
  try {
    const { jobName, podName } = req.params;
    const logFilePath = path.join(LOGS_BASE_DIR, jobName, `${podName}.log`);
    
    if (fs.existsSync(logFilePath)) {
      res.download(logFilePath, `${podName}.log`, (err) => {
        if (err) {
          console.error('Error downloading log file:', err);
          res.status(500).json({ 
            success: false, 
            error: 'Failed to download log file' 
          });
        }
      });
    } else {
      res.status(404).json({ 
        success: false, 
        error: 'Log file not found',
        path: logFilePath
      });
    }
  } catch (error) {
    console.error('Error downloading log file:', error);
    res.status(500).json({ 
      success: false, 
      error: error.message 
    });
  }
});

// Ëé∑ÂèñÊó•ÂøóÊñá‰ª∂‰ø°ÊÅØ
app.get('/api/logs/:jobName/:podName/info', (req, res) => {
  try {
    const { jobName, podName } = req.params;
    const logFilePath = path.join(LOGS_BASE_DIR, jobName, `${podName}.log`);
    
    if (fs.existsSync(logFilePath)) {
      const stats = fs.statSync(logFilePath);
      res.json({
        success: true,
        info: {
          size: stats.size,
          created: stats.birthtime,
          modified: stats.mtime,
          path: logFilePath
        }
      });
    } else {
      res.status(404).json({ 
        success: false, 
        error: 'Log file not found' 
      });
    }
  } catch (error) {
    console.error('Error getting log file info:', error);
    res.status(500).json({ 
      success: false, 
      error: error.message 
    });
  }
});

// Âà†Èô§ÈÉ®ÁΩ≤ - ÊîπËøõÁâàÊú¨
app.post('/api/undeploy', async (req, res) => {
  try {
    const { modelTag, deleteType } = req.body;
    
    if (!modelTag) {
      return res.status(400).json({
        success: false,
        error: 'Model tag is required'
      });
    }
    
    console.log(`Undeploying model: ${modelTag}, type: ${deleteType}`);
    
    // ÊûÑÂª∫ÂèØËÉΩÁöÑËµÑÊ∫êÂêçÁß∞
    const possibleDeployments = [
      `vllm-${modelTag}-inference`,
      `sglang-${modelTag}-inference`,
      `olm-${modelTag}-inference`,
      `${modelTag}-inference`  // Â§áÁî®Ê†ºÂºè
    ];
    
    const possibleServices = [
      `vllm-${modelTag}-nlb`,
      `sglang-${modelTag}-nlb`,
      `olm-${modelTag}-nlb`,
      `${modelTag}-nlb`,
      `${modelTag}-service`  // Â§áÁî®Ê†ºÂºè
    ];
    
    let deleteCommands = [];
    let deletedResources = [];
    
    // Ê†πÊçÆÂà†Èô§Á±ªÂûãÂÜ≥ÂÆöÂà†Èô§Âì™‰∫õËµÑÊ∫ê
    if (deleteType === 'all' || deleteType === 'deployment') {
      possibleDeployments.forEach(deploymentName => {
        deleteCommands.push(`delete deployment ${deploymentName} --ignore-not-found=true`);
      });
      deletedResources.push('Deployment');
    }
    
    if (deleteType === 'all' || deleteType === 'service') {
      possibleServices.forEach(serviceName => {
        deleteCommands.push(`delete service ${serviceName} --ignore-not-found=true`);
      });
      deletedResources.push('Service');
    }
    
    // ÊâßË°åÂà†Èô§ÂëΩ‰ª§
    const results = [];
    let actuallyDeleted = 0;
    
    for (const command of deleteCommands) {
      try {
        const output = await executeKubectl(command);
        const success = !output.includes('not found');
        results.push({
          command,
          success: true,
          output: output.trim(),
          actuallyDeleted: success
        });
        if (success) actuallyDeleted++;
      } catch (error) {
        results.push({
          command,
          success: false,
          error: error.error || error.message,
          actuallyDeleted: false
        });
      }
    }
    
    // Á≠âÂæÖ‰∏Ä‰∏ãËÆ©ËµÑÊ∫êÂÆåÂÖ®Âà†Èô§
    if (actuallyDeleted > 0) {
      console.log(`Waiting for resources to be fully deleted...`);
      await new Promise(resolve => setTimeout(resolve, 2000));
    }
    
    // ÂπøÊí≠Âà†Èô§Áä∂ÊÄÅÊõ¥Êñ∞
    broadcast({
      type: 'undeployment',
      status: 'success',
      message: `Successfully deleted resources for ${modelTag} (${actuallyDeleted} resources)`,
      results: results
    });
    
    res.json({
      success: true,
      message: actuallyDeleted > 0 
        ? `Successfully deleted ${actuallyDeleted} resource(s)` 
        : 'No resources found to delete (may already be deleted)',
      deletedResources: deletedResources,
      results: results,
      modelTag: modelTag,
      actuallyDeleted: actuallyDeleted
    });
    
  } catch (error) {
    console.error('Undeploy error:', error);
    
    broadcast({
      type: 'undeployment',
      status: 'error',
      message: `Failed to undeploy ${req.body.modelTag}: ${error.message}`
    });
    
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// Ëé∑ÂèñÈÉ®ÁΩ≤ËØ¶ÁªÜ‰ø°ÊÅØÔºàÂåÖÂê´Ê®°ÂûãÂÖÉÊï∞ÊçÆÔºâ
app.get('/api/deployment-details', async (req, res) => {
  try {
    console.log('Fetching deployment details with metadata...');
    
    // Ëé∑ÂèñÊâÄÊúâdeployment
    const deploymentsOutput = await executeKubectl('get deployments -o json');
    const deployments = JSON.parse(deploymentsOutput);
    
    // Ëé∑ÂèñÊâÄÊúâservice
    const servicesOutput = await executeKubectl('get services -o json');
    const services = JSON.parse(servicesOutput);
    
    // ËøáÊª§Âá∫Ê®°ÂûãÁõ∏ÂÖ≥ÁöÑÈÉ®ÁΩ≤Âπ∂ÊèêÂèñÂÖÉÊï∞ÊçÆ
    const modelDeployments = deployments.items
      .filter(deployment => 
        deployment.metadata.name.includes('vllm') || 
        deployment.metadata.name.includes('olm') ||
        deployment.metadata.name.includes('inference')
      )
      .map(deployment => {
        const labels = deployment.metadata.labels || {};
        const appLabel = labels.app;
        
        // Êü•ÊâæÂØπÂ∫îÁöÑservice
        const matchingService = services.items.find(service => 
          service.spec.selector?.app === appLabel
        );
        
        // ‰ªéÊ†áÁ≠æ‰∏≠ÊèêÂèñÊ®°Âûã‰ø°ÊÅØ
        const modelType = labels['model-type'] || 'unknown';
        const encodedModelId = labels['model-id'] || 'unknown';
        const modelTag = labels['model-tag'] || 'unknown';
        
        // Á°ÆÂÆöÊúÄÁªàÁöÑÊ®°ÂûãID - ‰ºòÂÖà‰ªéÂÆπÂô®ÂëΩ‰ª§‰∏≠ÊèêÂèñÂéüÂßãID
        let modelId = 'unknown';
        
        // ÂØπ‰∫éVLLMÈÉ®ÁΩ≤Ôºå‰ªéÂÆπÂô®ÂëΩ‰ª§‰∏≠ÊèêÂèñÂéüÂßãÊ®°ÂûãID
        if (modelType === 'vllm') {
          try {
            const containers = deployment.spec?.template?.spec?.containers || [];
            const vllmContainer = containers.find(c => c.name === 'vllm-openai');
            if (vllmContainer && vllmContainer.command) {
              const command = vllmContainer.command;
              
              // 1. ‰ºòÂÖàÊ£ÄÊü•Êñ∞ÁöÑ vllm serve Ê†ºÂºè
              const serveIndex = command.findIndex(arg => arg === 'serve');
              if (serveIndex !== -1 && serveIndex + 1 < command.length) {
                // Ê£ÄÊü•Ââç‰∏Ä‰∏™ÂèÇÊï∞ÊòØÂê¶ÊòØ vllm Áõ∏ÂÖ≥
                if (serveIndex > 0 && command[serveIndex - 1].includes('vllm')) {
                  const modelPath = command[serveIndex + 1];
                  // Á°Æ‰øù‰∏çÊòØ‰ª• -- ÂºÄÂ§¥ÁöÑÂèÇÊï∞
                  if (!modelPath.startsWith('--')) {
                    modelId = modelPath;
                  }
                }
              }
              
              // 2. Â¶ÇÊûúÊ≤°ÊâæÂà∞ÔºåÊ£ÄÊü•‰º†ÁªüÁöÑ --model ÂèÇÊï∞
              if (modelId === 'unknown') {
                const modelIndex = command.findIndex(arg => arg === '--model');
                if (modelIndex !== -1 && modelIndex + 1 < command.length) {
                  modelId = command[modelIndex + 1]; // Ëé∑Âèñ--modelÂèÇÊï∞ÂêéÁöÑÂÄº
                }
              }
            }
          } catch (error) {
            console.log('Failed to extract model ID from VLLM command:', error.message);
          }
        }
        
        // ÂØπ‰∫éOllamaÈÉ®ÁΩ≤Ôºå‰ªépostStartÁîüÂëΩÂë®ÊúüÈí©Â≠ê‰∏≠ÊèêÂèñÊ®°ÂûãID
        if (modelType === 'ollama' && modelId === 'unknown') {
          try {
            const containers = deployment.spec?.template?.spec?.containers || [];
            const ollamaContainer = containers.find(c => c.name === 'ollama');
            if (ollamaContainer && ollamaContainer.lifecycle?.postStart?.exec?.command) {
              const command = ollamaContainer.lifecycle.postStart.exec.command;
              // Êü•ÊâæÂåÖÂê´"ollama pull"ÁöÑÂëΩ‰ª§
              const commandStr = command.join(' ');
              const pullMatch = commandStr.match(/ollama pull ([^\s\\]+)/);
              if (pullMatch) {
                modelId = pullMatch[1]; // ÊèêÂèñÊ®°ÂûãID
                console.log('Extracted Ollama model ID from postStart:', modelId);
              }
            }
          } catch (error) {
            console.log('Failed to extract model ID from Ollama postStart command:', error.message);
          }
        }
        
        // ÂØπ‰∫éÊó†Ê≥ïÊèêÂèñÁöÑÊÉÖÂÜµÔºå‰ΩøÁî®Ëß£Á†ÅÈÄªËæë
        if (modelId === 'unknown' && encodedModelId !== 'unknown') {
          modelId = decodeModelIdFromLabel(encodedModelId);
        }
        
        // Ëé∑ÂèñÊúçÂä°URL
        let serviceUrl = '';
        if (matchingService) {
          const ingress = matchingService.status?.loadBalancer?.ingress?.[0];
          if (ingress) {
            const host = ingress.hostname || ingress.ip;
            const port = matchingService.spec.ports?.[0]?.port || 8000;
            serviceUrl = `http://${host}:${port}`;
          }
        }
        
        return {
          deploymentName: deployment.metadata.name,
          serviceName: matchingService?.metadata.name || 'N/A',
          modelType: modelType,
          modelId: modelId,
          modelTag: modelTag,
          serviceUrl: serviceUrl,
          status: deployment.status.readyReplicas === deployment.spec.replicas ? 'Ready' : 'Pending',
          replicas: deployment.spec.replicas,
          readyReplicas: deployment.status.readyReplicas || 0,
          hasService: !!matchingService,
          isExternal: matchingService?.metadata?.annotations?.['service.beta.kubernetes.io/aws-load-balancer-scheme'] === 'internet-facing'
        };
      });
    
    console.log('Deployment details fetched:', modelDeployments.length, 'deployments');
    res.json(modelDeployments);
    
  } catch (error) {
    console.error('Deployment details fetch error:', error);
    res.status(500).json({ error: error.message });
  }
});

// Ëé∑ÂèñÂ∑≤ÈÉ®ÁΩ≤ÁöÑÊ®°ÂûãÂàóË°®
app.get('/api/deployments', async (req, res) => {
  try {
    console.log('Fetching deployments...');
    
    // Ëé∑ÂèñÊâÄÊúâdeployment
    const deploymentsOutput = await executeKubectl('get deployments -o json');
    const deployments = JSON.parse(deploymentsOutput);
    
    // Ëé∑ÂèñÊâÄÊúâservice
    const servicesOutput = await executeKubectl('get services -o json');
    const services = JSON.parse(servicesOutput);
    
    // ËøáÊª§Âá∫VLLMÂíåOllamaÁõ∏ÂÖ≥ÁöÑÈÉ®ÁΩ≤
    const modelDeployments = deployments.items.filter(deployment => 
      deployment.metadata.name.includes('vllm') || 
      deployment.metadata.name.includes('olm') ||
      deployment.metadata.name.includes('inference')
    );
    
    // ‰∏∫ÊØè‰∏™ÈÉ®ÁΩ≤ÂåπÈÖçÂØπÂ∫îÁöÑservice
    const deploymentList = modelDeployments.map(deployment => {
      const appLabel = deployment.metadata.labels?.app;
      const matchingService = services.items.find(service => 
        service.spec.selector?.app === appLabel
      );
      
      // ‰ªédeploymentÂêçÁß∞ÊèêÂèñmodel tagÂíåÁ±ªÂûã
      const deploymentName = deployment.metadata.name;
      let modelTag = 'unknown';
      let deploymentType = 'unknown';
      
      if (deploymentName.startsWith('vllm-') && deploymentName.endsWith('-inference')) {
        modelTag = deploymentName.slice(5, -10); // ÁßªÈô§ 'vllm-' ÂâçÁºÄÂíå '-inference' ÂêéÁºÄ
        deploymentType = 'VLLM';
      } else if (deploymentName.startsWith('sglang-') && deploymentName.endsWith('-inference')) {
        modelTag = deploymentName.slice(7, -10); // ÁßªÈô§ 'sglang-' ÂâçÁºÄÂíå '-inference' ÂêéÁºÄ
        deploymentType = 'SGLANG';
      } else if (deploymentName.startsWith('olm-') && deploymentName.endsWith('-inference')) {
        modelTag = deploymentName.slice(4, -10); // ÁßªÈô§ 'olm-' ÂâçÁºÄÂíå '-inference' ÂêéÁºÄ
        deploymentType = 'Ollama';
      }
      
      // Ê£ÄÊü•ÊòØÂê¶‰∏∫externalËÆøÈóÆ
      const isExternal = matchingService?.metadata?.annotations?.['service.beta.kubernetes.io/aws-load-balancer-scheme'] === 'internet-facing';
      
      return {
        modelTag,
        deploymentType,
        deploymentName: deployment.metadata.name,
        serviceName: matchingService?.metadata.name || 'N/A',
        replicas: deployment.spec.replicas,
        readyReplicas: deployment.status.readyReplicas || 0,
        status: deployment.status.readyReplicas === deployment.spec.replicas ? 'Ready' : 'Pending',
        createdAt: deployment.metadata.creationTimestamp,
        hasService: !!matchingService,
        serviceType: matchingService?.spec.type || 'N/A',
        isExternal: isExternal,
        externalIP: matchingService?.status?.loadBalancer?.ingress?.[0]?.hostname || 
                   matchingService?.status?.loadBalancer?.ingress?.[0]?.ip || 'Pending'
      };
    });
    
    console.log('Deployments fetched:', deploymentList.length, 'model deployments');
    res.json(deploymentList);
    
  } catch (error) {
    console.error('Deployments fetch error:', error);
    res.status(500).json({ error: error.message });
  }
});

// ÊµãËØïÊ®°ÂûãAPIÔºàÁîüÊàêcURLÂëΩ‰ª§Ôºâ
app.post('/api/test-model', async (req, res) => {
  const { serviceUrl, payload } = req.body;
  
  try {
    let parsedPayload;
    
    try {
      parsedPayload = JSON.parse(payload);
    } catch (error) {
      return res.status(400).json({ error: 'Invalid JSON payload' });
    }
    
    const curlCommand = `curl -X POST "${serviceUrl}" \\
  -H "Content-Type: application/json" \\
  -d '${JSON.stringify(parsedPayload, null, 2)}'`;
    
    res.json({
      curlCommand,
      fullUrl: serviceUrl,
      message: 'Use the curl command to test your model'
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// WebSocketËøûÊé•Â§ÑÁêÜ - ‰ºòÂåñÁâàÊú¨ÔºåÂáèÂ∞ëÊó•ÂøóÊ±°Êüì
wss.on('connection', (ws) => {
  console.log('WebSocket client connected');
  
  // ÂèëÈÄÅÁä∂ÊÄÅÊõ¥Êñ∞ÁöÑÂáΩÊï∞
  const sendStatusUpdate = async () => {
    try {
      const [pods, services] = await Promise.all([
        executeKubectl('get pods -o json').then(output => JSON.parse(output).items),
        executeKubectl('get services -o json').then(output => JSON.parse(output).items)
      ]);
      
      const statusData = {
        type: 'status_update',
        pods,
        services,
        timestamp: new Date().toISOString()
      };
      
      if (ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify(statusData));
        console.log(`üì° Status update sent: ${pods.length} pods, ${services.length} services`);
      }
    } catch (error) {
      console.error('‚ùå Error fetching status for WebSocket:', error);
    }
  };
  
  // üöÄ ‰ºòÂåñÔºöÂè™Âú®ËøûÊé•Êó∂ÂèëÈÄÅ‰∏ÄÊ¨°ÂàùÂßãÁä∂ÊÄÅÔºå‰∏çÂÜçÂÆöÊó∂ÂèëÈÄÅ
  sendStatusUpdate();
  
  // Â≠òÂÇ®WebSocketËøûÊé•ÔºåÁî®‰∫éÊåâÈúÄÂπøÊí≠
  ws.isAlive = true;
  ws.lastActivity = Date.now();
  
  // Â§ÑÁêÜWebSocketÊ∂àÊÅØ
  ws.on('message', (message) => {
    try {
      const data = JSON.parse(message);
      ws.lastActivity = Date.now();
      
      // üéØ ÊåâÈúÄÂ§ÑÁêÜ‰∏çÂêåÁ±ªÂûãÁöÑÊ∂àÊÅØ
      switch (data.type) {
        case 'request_status_update':
          // ÂÆ¢Êà∑Á´Ø‰∏ªÂä®ËØ∑Ê±ÇÁä∂ÊÄÅÊõ¥Êñ∞
          console.log('üì° Client requested status update');
          sendStatusUpdate();
          break;
          
        case 'start_log_stream':
          console.log(`üîÑ Starting log stream for ${data.jobName}/${data.podName}`);
          startLogStream(ws, data.jobName, data.podName);
          break;
          
        case 'stop_log_stream':
          console.log(`‚èπÔ∏è Stopping log stream for ${data.jobName}/${data.podName}`);
          stopLogStream(ws, data.jobName, data.podName);
          break;
          
        case 'stop_all_log_streams':
          console.log('‚èπÔ∏è Stopping all log streams');
          stopAllLogStreams(ws);
          break;
          
        case 'ping':
          // ÂøÉË∑≥Ê£ÄÊµã
          if (ws.readyState === WebSocket.OPEN) {
            ws.send(JSON.stringify({ type: 'pong', timestamp: new Date().toISOString() }));
          }
          break;
          
        default:
          console.log('üì® Received WebSocket message:', data.type);
      }
    } catch (error) {
      console.error('‚ùå Error parsing WebSocket message:', error);
    }
  });
  
  // ÂøÉË∑≥Ê£ÄÊµã
  ws.on('pong', () => {
    ws.isAlive = true;
    ws.lastActivity = Date.now();
  });
  
  ws.on('close', () => {
    console.log('üîå WebSocket client disconnected');
    // Ê∏ÖÁêÜËØ•ËøûÊé•ÁöÑÊâÄÊúâÊó•ÂøóÊµÅ
    stopAllLogStreams(ws);
  });
  
  ws.on('error', (error) => {
    console.error('‚ùå WebSocket error:', error);
    // Ê∏ÖÁêÜËØ•ËøûÊé•ÁöÑÊâÄÊúâÊó•ÂøóÊµÅ
    stopAllLogStreams(ws);
  });
});

// üöÄ ÂπøÊí≠ÂáΩÊï∞ - ÂêëÊâÄÊúâËøûÊé•ÁöÑÂÆ¢Êà∑Á´ØÂèëÈÄÅÊ∂àÊÅØ
function broadcast(message) {
  const messageStr = JSON.stringify({
    ...message,
    timestamp: new Date().toISOString()
  });
  
  let sentCount = 0;
  wss.clients.forEach((client) => {
    if (client.readyState === WebSocket.OPEN) {
      client.send(messageStr);
      sentCount++;
    }
  });
  
  if (sentCount > 0) {
    console.log(`üì° Broadcast sent to ${sentCount} clients:`, message.type);
  }
}

// üîÑ ÊåâÈúÄÁä∂ÊÄÅÊõ¥Êñ∞ÂπøÊí≠
function broadcastStatusUpdate() {
  const message = {
    type: 'request_status_update_broadcast',
    source: 'server'
  };
  broadcast(message);
}

// ‚ù§Ô∏è WebSocketÂøÉË∑≥Ê£ÄÊµã - ÊØè30ÁßíÊ£ÄÊü•‰∏ÄÊ¨°ËøûÊé•Áä∂ÊÄÅ
const heartbeatInterval = setInterval(() => {
  const now = Date.now();
  let activeConnections = 0;
  
  wss.clients.forEach((ws) => {
    if (ws.readyState === WebSocket.OPEN) {
      // Ê£ÄÊü•ËøûÊé•ÊòØÂê¶Ê¥ªË∑ÉÔºà5ÂàÜÈíüÂÜÖÊúâÊ¥ªÂä®Ôºâ
      if (now - ws.lastActivity < 300000) {
        ws.ping();
        activeConnections++;
      } else {
        console.log('üîå Terminating inactive WebSocket connection');
        ws.terminate();
      }
    }
  });
  
  // Âè™Âú®ÊúâËøûÊé•Êó∂ËæìÂá∫ÂøÉË∑≥Êó•Âøó
  if (activeConnections > 0) {
    console.log(`‚ù§Ô∏è WebSocket heartbeat: ${activeConnections} active connections`);
  }
}, 30000);

// üßπ ËøõÁ®ãÊ∏ÖÁêÜÂáΩÊï∞ - ‰ºòÂåñÁâàÊú¨
process.on('SIGTERM', () => {
  console.log('üõë Received SIGTERM signal - Server shutting down gracefully...');
  gracefulShutdown('SIGTERM');
});

process.on('SIGINT', () => {
  console.log('üõë Received SIGINT signal (Ctrl+C) - Server shutting down gracefully...');
  gracefulShutdown('SIGINT');
});

process.on('uncaughtException', (error) => {
  console.error('‚ùå Uncaught Exception:', error);
  console.error('Stack trace:', error.stack);
  gracefulShutdown('uncaughtException');
});

process.on('unhandledRejection', (reason, promise) => {
  console.error('‚ùå Unhandled Rejection at:', promise, 'reason:', reason);
  gracefulShutdown('unhandledRejection');
});

// ‰ºòÈõÖÂÖ≥Èó≠ÂáΩÊï∞
function gracefulShutdown(signal) {
  console.log(`üîÑ Starting graceful shutdown (signal: ${signal})...`);
  
  // Ê∏ÖÁêÜWebSocketÂøÉË∑≥Ê£ÄÊµã
  if (typeof heartbeatInterval !== 'undefined') {
    clearInterval(heartbeatInterval);
    console.log('‚úÖ WebSocket heartbeat interval cleared');
  }
  
  // ÂÖ≥Èó≠WebSocketÊúçÂä°Âô®
  if (wss) {
    console.log(`üì° Closing WebSocket server (${wss.clients.size} active connections)...`);
    wss.close(() => {
      console.log('‚úÖ WebSocket server closed');
    });
  }
  
  // Ê∏ÖÁêÜÊ¥ªË∑ÉÁöÑÊó•ÂøóÊµÅ
  if (activeLogStreams && activeLogStreams.size > 0) {
    console.log(`üßπ Cleaning up ${activeLogStreams.size} active log streams...`);
    activeLogStreams.clear();
    console.log('‚úÖ Log streams cleaned up');
  }
  
  console.log('‚úÖ Graceful shutdown completed');
  
  // Áªô‰∏Ä‰∫õÊó∂Èó¥ËÆ©Ê∏ÖÁêÜÂÆåÊàêÔºåÁÑ∂ÂêéÈÄÄÂá∫
  setTimeout(() => {
    process.exit(signal === 'uncaughtException' || signal === 'unhandledRejection' ? 1 : 0);
  }, 1000);
}

// ÂêØÂä®podÊó•ÂøóÊµÅ
function startLogStream(ws, jobName, podName) {
  const streamKey = `${jobName}-${podName}`;
  
  // Â¶ÇÊûúÂ∑≤ÁªèÊúâËØ•podÁöÑÊó•ÂøóÊµÅÔºåÂÖàÂÅúÊ≠¢ÂÆÉ
  if (activeLogStreams.has(streamKey)) {
    stopLogStream(ws, jobName, podName);
  }
  
  console.log(`Starting log stream for pod: ${podName} in job: ${jobName}`);
  
  // ÂàõÂª∫Êó•ÂøóÊñá‰ª∂Ë∑ØÂæÑ
  const logFilePath = ensureLogDirectory(jobName, podName);
  const logStream = fs.createWriteStream(logFilePath, { flags: 'a' });
  
  // ÂêØÂä®kubectl logsÂëΩ‰ª§
  const logProcess = spawn('kubectl', ['logs', '-f', podName], {
    stdio: ['pipe', 'pipe', 'pipe']
  });
  
  // Â≠òÂÇ®ËøõÁ®ãÂºïÁî®ÂíåÊñá‰ª∂ÊµÅ
  activeLogStreams.set(streamKey, {
    process: logProcess,
    logStream: logStream,
    ws: ws,
    jobName: jobName,
    podName: podName
  });
  
  // Â§ÑÁêÜÊ†áÂáÜËæìÂá∫
  logProcess.stdout.on('data', (data) => {
    const logLine = data.toString();
    const timestamp = new Date().toISOString();
    
    // ÂÜôÂÖ•Êñá‰ª∂ÔºàÂ∏¶Êó∂Èó¥Êà≥Ôºâ
    logStream.write(`[${timestamp}] ${logLine}`);
    
    // ÂèëÈÄÅÂà∞ÂâçÁ´Ø
    if (ws.readyState === WebSocket.OPEN) {
      ws.send(JSON.stringify({
        type: 'log_data',
        jobName: jobName,
        podName: podName,
        data: logLine,
        timestamp: timestamp
      }));
    }
  });
  
  // Â§ÑÁêÜÊ†áÂáÜÈîôËØØ
  logProcess.stderr.on('data', (data) => {
    const errorLine = data.toString();
    const timestamp = new Date().toISOString();
    
    console.error(`Log stream error for ${podName}:`, errorLine);
    
    // ÂÜôÂÖ•ÈîôËØØÂà∞Êñá‰ª∂
    logStream.write(`[${timestamp}] ERROR: ${errorLine}`);
    
    if (ws.readyState === WebSocket.OPEN) {
      ws.send(JSON.stringify({
        type: 'log_error',
        jobName: jobName,
        podName: podName,
        error: errorLine,
        timestamp: timestamp
      }));
    }
  });
  
  // Â§ÑÁêÜËøõÁ®ãÈÄÄÂá∫
  logProcess.on('close', (code) => {
    console.log(`Log stream for ${podName} closed with code: ${code}`);
    
    // ÂÖ≥Èó≠Êñá‰ª∂ÊµÅ
    logStream.end();
    activeLogStreams.delete(streamKey);
    
    if (ws.readyState === WebSocket.OPEN) {
      ws.send(JSON.stringify({
        type: 'log_stream_closed',
        jobName: jobName,
        podName: podName,
        code: code,
        timestamp: new Date().toISOString()
      }));
    }
  });
  
  // Â§ÑÁêÜËøõÁ®ãÈîôËØØ
  logProcess.on('error', (error) => {
    console.error(`Log stream process error for ${podName}:`, error);
    
    // ÂÖ≥Èó≠Êñá‰ª∂ÊµÅ
    logStream.end();
    activeLogStreams.delete(streamKey);
    
    if (ws.readyState === WebSocket.OPEN) {
      ws.send(JSON.stringify({
        type: 'log_stream_error',
        jobName: jobName,
        podName: podName,
        error: error.message,
        timestamp: new Date().toISOString()
      }));
    }
  });
}

// ÂÅúÊ≠¢ÁâπÂÆöpodÁöÑÊó•ÂøóÊµÅ
function stopLogStream(ws, jobName, podName) {
  const streamKey = `${jobName}-${podName}`;
  const streamInfo = activeLogStreams.get(streamKey);
  
  if (streamInfo) {
    console.log(`Stopping log stream for pod: ${podName}`);
    streamInfo.process.kill('SIGTERM');
    
    // ÂÖ≥Èó≠Êñá‰ª∂ÊµÅ
    if (streamInfo.logStream) {
      streamInfo.logStream.end();
    }
    
    activeLogStreams.delete(streamKey);
    
    if (ws.readyState === WebSocket.OPEN) {
      ws.send(JSON.stringify({
        type: 'log_stream_stopped',
        jobName: jobName,
        podName: podName,
        timestamp: new Date().toISOString()
      }));
    }
  }
}

// ÂÅúÊ≠¢Êüê‰∏™WebSocketËøûÊé•ÁöÑÊâÄÊúâÊó•ÂøóÊµÅ
function stopAllLogStreams(ws) {
  const streamsToStop = [];
  
  // ‰ªéÁªü‰∏ÄÊó•ÂøóÊµÅ‰∏≠ÁßªÈô§ËØ•WebSocketËøûÊé•
  unifiedLogStreams.forEach((stream, streamKey) => {
    if (stream.webSockets.has(ws)) {
      const [jobName, podName] = streamKey.split('-');
      streamsToStop.push({ jobName, podName });
    }
  });
  
  // ÁßªÈô§WebSocketËøûÊé•
  streamsToStop.forEach(({ jobName, podName }) => {
    removeWebSocketFromLogStream(ws, jobName, podName);
  });
  
  if (streamsToStop.length > 0) {
    console.log(`üßπ Cleaned up ${streamsToStop.length} log streams for disconnected WebSocket`);
  }
}

const S3StorageManager = require('./s3-storage-manager');
const s3StorageManager = new S3StorageManager();

// S3Â≠òÂÇ®ÁÆ°ÁêÜAPI
app.get('/api/s3-storages', async (req, res) => {
  const result = await s3StorageManager.getStorages();
  res.json(result);
});

app.post('/api/s3-storages', async (req, res) => {
  const result = await s3StorageManager.createStorage(req.body);
  if (result.success) {
    broadcast({
      type: 's3_storage_created',
      status: 'success',
      message: `S3 storage ${req.body.name} created successfully`
    });
  }
  res.json(result);
});

app.delete('/api/s3-storages/:name', async (req, res) => {
  const result = await s3StorageManager.deleteStorage(req.params.name);
  if (result.success) {
    broadcast({
      type: 's3_storage_deleted',
      status: 'success',
      message: `S3 storage ${req.params.name} deleted successfully`
    });
  }
  res.json(result);
});

// Â¢ûÂº∫ÁöÑÊ®°Âûã‰∏ãËΩΩAPI
app.post('/api/download-model-enhanced', async (req, res) => {
  try {
    const { modelId, hfToken, resources, s3Storage } = req.body;
    
    if (!modelId) {
      return res.json({ success: false, error: 'Model ID is required' });
    }

    console.log(`üöÄ Starting enhanced model download: ${modelId}`);
    console.log(`üìä Resources: CPU=${resources.cpu}, Memory=${resources.memory}GB`);
    console.log(`üíæ S3 Storage: ${s3Storage}`);

    // ÁîüÊàêÂ¢ûÂº∫ÁöÑ‰∏ãËΩΩJob
    const jobResult = await s3StorageManager.generateEnhancedDownloadJob({
      modelId,
      hfToken,
      resources,
      s3Storage
    });

    if (!jobResult.success) {
      return res.json({ success: false, error: jobResult.error });
    }

    // Á°Æ‰øùdeploymentsÁõÆÂΩïÂ≠òÂú®
    const deploymentsDir = path.join(__dirname, '..', 'deployments');
    await fs.ensureDir(deploymentsDir);
    
    // ‰øùÂ≠òÁîüÊàêÁöÑYAMLÊñá‰ª∂Âà∞deploymentsÁõÆÂΩï
    const modelTag = modelId.replace(/[^a-zA-Z0-9]/g, '-').toLowerCase();
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const deploymentFile = path.join(deploymentsDir, `enhanced-model-download-${modelTag}-${timestamp}.yaml`);
    await fs.writeFile(deploymentFile, jobResult.yamlContent);
    
    console.log(`üìÅ Saved deployment template: ${deploymentFile}`);

    // Â∫îÁî®JobÂà∞Kubernetes
    const tempFile = `/tmp/enhanced-download-job-${Date.now()}.yaml`;
    fs.writeFileSync(tempFile, jobResult.yamlContent);

    exec(`kubectl apply -f ${tempFile}`, (error, stdout, stderr) => {
      fs.removeSync(tempFile);
      
      if (error) {
        console.error('‚ùå Failed to create enhanced download job:', stderr);
        broadcast({
          type: 'model_download',
          status: 'error',
          message: `Failed to start enhanced model download: ${stderr}`
        });
        return res.json({ success: false, error: stderr });
      }

      console.log('‚úÖ Enhanced model download job created successfully');
      broadcast({
        type: 'model_download',
        status: 'success',
        message: `Enhanced model download started: ${modelId}`,
        jobName: jobResult.jobName
      });

      res.json({ 
        success: true, 
        message: 'Enhanced model download job created successfully',
        jobName: jobResult.jobName,
        deploymentFile: path.basename(deploymentFile)
      });
    });

  } catch (error) {
    console.error('‚ùå Error in enhanced model download:', error);
    res.json({ success: false, error: error.message });
  }
});

// Ê®°Âûã‰∏ãËΩΩAPI
app.post('/api/download-model', async (req, res) => {
  try {
    const { modelId, hfToken } = req.body;
    
    if (!modelId) {
      return res.json({ success: false, error: 'Model ID is required' });
    }
    
    console.log(`Starting model download for: ${modelId}`);
    
    // ËØªÂèñHF‰∏ãËΩΩÊ®°Êùø
    const templatePath = path.join(__dirname, '..', 'templates', 'hf-download-template.yaml');
    let template = await fs.readFile(templatePath, 'utf8');
    
    // ÁîüÊàêÊ®°ÂûãÊ†áÁ≠æ
    const modelTag = generateModelTag(modelId);
    
    // ÊõøÊç¢Âü∫Êú¨ÂèòÈáè
    const replacements = {
      'HF_MODEL_ID': modelId,
      'MODEL_TAG': modelTag
    };
    
    // Â§ÑÁêÜHF TokenÁéØÂ¢ÉÂèòÈáè
    if (hfToken && hfToken.trim()) {
      const tokenEnv = `
        - name: HF_TOKEN
          value: "${hfToken.trim()}"`;
      template = template.replace('env:HF_TOKEN_ENV', `env:${tokenEnv}`);
      
      // ÂêåÊó∂Âú®hf downloadÂëΩ‰ª§‰∏≠ÂêØÁî®token
      template = template.replace('#  --token=$HF_TOKEN', '          --token=$HF_TOKEN \\');
    } else {
      // ÁßªÈô§HF_TOKEN_ENVÂç†‰ΩçÁ¨¶Ôºå‰øùÁïôÂÖ∂‰ªñÁéØÂ¢ÉÂèòÈáè
      template = template.replace('      env:HF_TOKEN_ENV', '      env:');
    }
    
    // ÊõøÊç¢ÂÖ∂‰ªñÂèòÈáè
    Object.keys(replacements).forEach(key => {
      const regex = new RegExp(key, 'g');
      template = template.replace(regex, replacements[key]);
    });
    
    // Á°Æ‰øùdeploymentsÁõÆÂΩïÂ≠òÂú®
    const deploymentsDir = path.join(__dirname, '..', 'deployments');
    await fs.ensureDir(deploymentsDir);
    
    // ‰øùÂ≠òÁîüÊàêÁöÑYAMLÊñá‰ª∂
    const deploymentFile = path.join(deploymentsDir, `model-download-${modelTag}.yaml`);
    await fs.writeFile(deploymentFile, template);
    
    console.log(`Generated deployment file: ${deploymentFile}`);
    
    // Â∫îÁî®Âà∞Kubernetes
    try {
      const result = await executeKubectl(`apply -f "${deploymentFile}"`);
      console.log('kubectl apply result:', result);
      
      // ÂπøÊí≠ÈÉ®ÁΩ≤Áä∂ÊÄÅÊõ¥Êñ∞
      broadcast({
        type: 'model_download',
        status: 'success',
        message: `Model download started for ${modelId}`,
        modelId: modelId,
        modelTag: modelTag
      });
      
      res.json({ 
        success: true, 
        message: `Model download initiated for ${modelId}`,
        modelTag: modelTag
      });
      
    } catch (kubectlError) {
      console.error('kubectl apply error:', kubectlError);
      res.json({ 
        success: false, 
        error: `Failed to apply deployment: ${kubectlError.error || kubectlError}` 
      });
    }
    
  } catch (error) {
    console.error('Model download error:', error);
    res.json({ success: false, error: error.message });
  }
});

// S3Â≠òÂÇ®‰ø°ÊÅØAPI - ‰ªés3-pv PersistentVolumeËé∑ÂèñÊ°∂‰ø°ÊÅØ
app.get('/api/s3-storage', async (req, res) => {
  try {
    const { storage } = req.query;
    console.log(`üì¶ Fetching S3 storage content for: ${storage || 'default'}`);
    
    // Ëé∑ÂèñÂ≠òÂÇ®ÈÖçÁΩÆ
    const storageResult = await s3StorageManager.getStorages();
    if (!storageResult.success) {
      return res.json({ success: false, error: 'Failed to get storage configurations' });
    }
    
    // ÊâæÂà∞ÂØπÂ∫îÁöÑÂ≠òÂÇ®ÈÖçÁΩÆ
    const selectedStorage = storageResult.storages.find(s => s.pvcName === storage) || 
                           storageResult.storages.find(s => s.pvcName === 's3-claim') ||
                           storageResult.storages[0];
    
    if (!selectedStorage) {
      return res.json({ 
        success: true, 
        data: [], 
        bucketInfo: { bucket: 'No storage configured', region: 'Unknown' }
      });
    }
    
    console.log(`üì¶ Using storage: ${selectedStorage.name} -> ${selectedStorage.bucketName}`);
    
    // ‰ΩøÁî®AWS CLIËé∑ÂèñS3ÂÜÖÂÆπ
    let s3Data = [];
    const region = selectedStorage.region || 'us-west-2';
    const awsCommand = `aws s3 ls s3://${selectedStorage.bucketName}/ --region ${region}`;
    
    console.log(`üîç Executing: ${awsCommand}`);
    
    try {
      const { exec } = require('child_process');
      const { promisify } = require('util');
      const execAsync = promisify(exec);
      
      const { stdout, stderr } = await execAsync(awsCommand);
      
      if (stderr) {
        console.warn('AWS CLI stderr:', stderr);
      }
      
      console.log('AWS CLI stdout:', stdout);
      
      if (stdout) {
        const lines = stdout.split('\n').filter(line => line.trim());
        
        for (const line of lines) {
          const trimmed = line.trim();
          if (!trimmed) continue;
          
          if (trimmed.startsWith('PRE ')) {
            // Êñá‰ª∂Â§πÊ†ºÂºè: "PRE folder-name/"
            const folderName = trimmed.substring(4); // ÂéªÊéâ "PRE "
            s3Data.push({
              key: folderName,
              type: 'folder',
              size: null,
              lastModified: new Date().toISOString()
            });
          } else {
            // Êñá‰ª∂Ê†ºÂºè: "2025-08-15 09:18:57 0 filename"
            const parts = trimmed.split(/\s+/);
            if (parts.length >= 4) {
              const date = parts[0];
              const time = parts[1];
              const size = parts[2];
              const name = parts.slice(3).join(' ');
              
              s3Data.push({
                key: name,
                type: 'file',
                size: parseInt(size) || 0,
                lastModified: new Date(`${date} ${time}`).toISOString(),
                storageClass: 'STANDARD'
              });
            }
          }
        }
      }
      
      console.log(`üìä Found ${s3Data.length} items in S3`);
      
    } catch (awsError) {
      console.error('AWS CLI error:', awsError);
      throw new Error(`Failed to list S3 contents: ${awsError.message}`);
    }
    
    res.json({
      success: true,
      data: s3Data,
      bucketInfo: {
        bucket: selectedStorage.bucketName,
        region: selectedStorage.region || 'Unknown',
        pvcName: selectedStorage.pvcName
      }
    });
    
  } catch (error) {
    console.error('‚ùå Error fetching S3 storage:', error);
    res.json({ success: false, error: error.message });
  }
});
app.get('/api/cluster/mlflow-info', (req, res) => {
  try {
    // ‰ΩøÁî®Â§öÈõÜÁæ§ÁÆ°ÁêÜÂô®Ëé∑ÂèñÊ¥ªË∑ÉÈõÜÁæ§ÁöÑMLflow‰ø°ÊÅØ
    const ClusterManager = require('./cluster-manager');
    const clusterManager = new ClusterManager();
    const activeCluster = clusterManager.getActiveCluster();
    
    if (!activeCluster) {
      return res.json({
        success: false,
        error: 'No active cluster found'
      });
    }

    // ‰ªéÊ¥ªË∑ÉÈõÜÁæ§ÁöÑÈÖçÁΩÆÁõÆÂΩïËØªÂèñMLflow‰ø°ÊÅØ
    const configDir = clusterManager.getClusterConfigDir(activeCluster);
    const mlflowInfoPath = path.join(configDir, 'mlflow-server-info.json');
    
    if (fs.existsSync(mlflowInfoPath)) {
      const fileContent = fs.readFileSync(mlflowInfoPath, 'utf8').trim();
      
      // Ê£ÄÊü•Êñá‰ª∂ÊòØÂê¶‰∏∫Á©∫
      if (!fileContent) {
        return res.json({
          success: true,
          data: {
            status: 'not_found',
            error: 'MLflow server info file is empty',
            clusterTag: activeCluster
          }
        });
      }
      
      let mlflowInfo;
      try {
        mlflowInfo = JSON.parse(fileContent);
      } catch (parseError) {
        return res.json({
          success: true,
          data: {
            status: 'error',
            error: 'Invalid JSON in MLflow server info file',
            clusterTag: activeCluster
          }
        });
      }
      
      // Ê£ÄÊü•Ëß£ÊûêÂêéÁöÑÂØπË±°ÊòØÂê¶‰∏∫Á©∫ÊàñÊó†Êïà
      if (!mlflowInfo || Object.keys(mlflowInfo).length === 0) {
        return res.json({
          success: true,
          data: {
            status: 'not_found',
            error: 'MLflow server info is empty',
            clusterTag: activeCluster
          }
        });
      }
      
      // ËøîÂõûÂâçÁ´ØÊúüÊúõÁöÑÊï∞ÊçÆÁªìÊûÑ
      res.json({
        success: true,
        data: {
          status: 'found',
          trackingServerArn: mlflowInfo.TrackingServerArn,
          trackingServerName: mlflowInfo.TrackingServerName,
          trackingServerUrl: mlflowInfo.TrackingServerUrl,
          trackingServerStatus: mlflowInfo.TrackingServerStatus,
          isActive: mlflowInfo.IsActive,
          mlflowVersion: mlflowInfo.MlflowVersion,
          artifactStoreUri: mlflowInfo.ArtifactStoreUri,
          trackingServerSize: mlflowInfo.TrackingServerSize,
          roleArn: mlflowInfo.RoleArn,
          creationTime: mlflowInfo.CreationTime,
          clusterTag: activeCluster,
          rawData: mlflowInfo // ‰øùÁïôÂéüÂßãÊï∞ÊçÆ‰ª•Â§áË∞ÉËØï
        }
      });
    } else {
      res.json({
        success: true,
        data: {
          status: 'not_found',
          error: `MLflow server info not found for cluster: ${activeCluster}`,
          clusterTag: activeCluster
        }
      });
    }
  } catch (error) {
    console.error('Error reading MLflow server info:', error);
    res.json({
      success: false,
      error: error.message
    });
  }
});

// Ê∏ÖÈô§Áä∂ÊÄÅÁºìÂ≠ò API

// Ëé∑Âèñ Step 1 Áä∂ÊÄÅ API

// Ëé∑ÂèñÊó•ÂøóÂÜÖÂÆπ API
// ÊóßÁöÑÊó•ÂøóAPI - Â∑≤Ë¢´Â§öÈõÜÁæ§APIÊõø‰ª£
/*
app.get('/api/cluster/logs/:step', (req, res) => {
  try {
    const { step } = req.params;
    const { offset = 0 } = req.query;
    
    const logContent = logManager.getCurrentLogContent(step);
    const statusFile = path.join(logManager.metadataDir, `${step}_status.json`);
    
    let status = { status: 'idle' };
    if (fs.existsSync(statusFile)) {
      status = JSON.parse(fs.readFileSync(statusFile, 'utf8'));
    }

    // ÊîØÊåÅÂ¢ûÈáèËØªÂèñÔºà‰ªéÊåáÂÆöÂÅèÁßªÈáèÂºÄÂßãÔºâ
    const newContent = logContent.slice(parseInt(offset));
    
    res.json({
      success: true,
      data: {
        content: newContent,
        fullContent: logContent,
        totalLength: logContent.length,
        status: status.status,
        timestamp: status.timestamp,
        logId: status.logId
      }
    });

  } catch (error) {
    console.error('Error reading logs:', error);
    res.json({
      success: false,
      error: error.message
    });
  }
});
*/

// Ëé∑ÂèñÂéÜÂè≤Êó•ÂøóÂàóË°®
app.get('/api/cluster/logs-history', (req, res) => {
  try {
    const logFiles = fs.readdirSync(logManager.logsDir)
      .filter(file => file.endsWith('.log'))
      .map(file => {
        const filePath = path.join(logManager.logsDir, file);
        const stats = fs.statSync(filePath);
        const [timestamp, step] = file.replace('.log', '').split('_');
        
        return {
          filename: file,
          step: step,
          timestamp: timestamp.replace(/_/g, 'T').replace(/-/g, ':'),
          size: stats.size,
          created: stats.birthtime,
          modified: stats.mtime
        };
      })
      .sort((a, b) => new Date(b.created) - new Date(a.created));

    res.json({
      success: true,
      data: logFiles
    });

  } catch (error) {
    console.error('Error getting log history:', error);
    res.json({
      success: false,
      error: error.message
    });
  }
});

// Ëé∑Âèñ CloudFormation Â†ÜÊ†àÁä∂ÊÄÅ - ‰ªé init_envs Ëá™Âä®ËØªÂèñÂ†ÜÊ†àÂêçÁß∞
// ==================== Â§öÈõÜÁæ§ÁÆ°ÁêÜ API ====================
// ÂºïÂÖ•Â§öÈõÜÁæ§ÁÆ°ÁêÜÊ®°Âùó
const MultiClusterAPIs = require('./multi-cluster-apis');
const MultiClusterStatus = require('./multi-cluster-status');

const multiClusterAPIs = new MultiClusterAPIs();
const multiClusterStatus = new MultiClusterStatus();

// Â§öÈõÜÁæ§ÁÆ°ÁêÜAPI
app.get('/api/multi-cluster/list', (req, res) => multiClusterAPIs.handleGetClusters(req, res));
app.post('/api/multi-cluster/switch', (req, res) => multiClusterAPIs.handleSwitchCluster(req, res));
app.post('/api/multi-cluster/switch-kubectl', (req, res) => multiClusterAPIs.handleSwitchKubectlConfig(req, res));

// ÈõÜÁæ§ÂØºÂÖ•API
app.post('/api/cluster/import', (req, res) => multiClusterAPIs.handleImportCluster(req, res));
app.post('/api/cluster/test-connection', (req, res) => multiClusterAPIs.handleTestConnection(req, res));

// ÈáçÂÜôÁé∞ÊúâÁöÑÈõÜÁæ§API‰ª•ÊîØÊåÅÂ§öÈõÜÁæ§
app.post('/api/cluster/save-config', (req, res) => multiClusterAPIs.handleSaveConfig(req, res));
app.post('/api/cluster/launch', (req, res) => multiClusterAPIs.handleLaunch(req, res));
app.post('/api/cluster/configure', (req, res) => multiClusterAPIs.handleConfigure(req, res));
app.get('/api/cluster/logs/:step', (req, res) => multiClusterAPIs.handleGetLogs(req, res));
app.get('/api/cluster/logs-history', (req, res) => multiClusterAPIs.handleGetLogsHistory(req, res));
app.post('/api/cluster/clear-status-cache', (req, res) => multiClusterAPIs.handleClearStatusCache(req, res));

// ÈáçÂÜôÁä∂ÊÄÅÊ£ÄÊü•API‰ª•ÊîØÊåÅÂ§öÈõÜÁæ§
app.get('/api/cluster/step1-status', (req, res) => multiClusterStatus.handleStep1Status(req, res));
app.get('/api/cluster/step2-status', (req, res) => multiClusterStatus.handleStep2Status(req, res));
app.get('/api/cluster/cloudformation-status', (req, res) => multiClusterStatus.handleCloudFormationStatus(req, res));

// ËäÇÁÇπÁªÑÁÆ°ÁêÜAPI
app.get('/api/cluster/nodegroups', async (req, res) => {
  try {
    const { exec } = require('child_process');
    const { promisify } = require('util');
    const execAsync = promisify(exec);
    const fs = require('fs');
    const path = require('path');
    
    const ClusterManager = require('./cluster-manager');
    const clusterManager = new ClusterManager();
    const activeClusterName = clusterManager.getActiveCluster();
    
    if (!activeClusterName) {
      return res.status(400).json({ error: 'No active cluster found' });
    }

    // ËØªÂèñÈõÜÁæ§ÈÖçÁΩÆÊñá‰ª∂
    const configDir = clusterManager.getClusterConfigDir(activeClusterName);
    const initEnvsPath = path.join(configDir, 'init_envs');
    
    if (!fs.existsSync(initEnvsPath)) {
      return res.status(400).json({ error: 'Cluster configuration file not found' });
    }

    // Ëß£Êûêinit_envsÊñá‰ª∂ - ‰ΩøÁî®shell sourceÊñπÂºè
    const getEnvVar = async (varName) => {
      const cmd = `source ${initEnvsPath} && echo $${varName}`;
      const result = await execAsync(cmd, { shell: '/bin/bash' });
      return result.stdout.trim();
    };
    
    const clusterName = await getEnvVar('EKS_CLUSTER_NAME') || activeClusterName;
    const region = await getEnvVar('AWS_REGION') || 'us-west-2';
    
    // Ëé∑ÂèñEKSËäÇÁÇπÁªÑ
    const eksCmd = `aws eks list-nodegroups --cluster-name ${clusterName} --region ${region} --output json`;
    const eksResult = await execAsync(eksCmd);
    const eksData = JSON.parse(eksResult.stdout);
    
    const eksNodeGroups = [];
    for (const nodegroupName of eksData.nodegroups || []) {
      const detailCmd = `aws eks describe-nodegroup --cluster-name ${clusterName} --nodegroup-name ${nodegroupName} --region ${region} --output json`;
      const detailResult = await execAsync(detailCmd);
      const nodegroup = JSON.parse(detailResult.stdout).nodegroup;
      
      // Ëé∑ÂèñÂÆû‰æãÁ±ªÂûãÔºåÂ¶ÇÊûú‰∏∫nullÂàô‰ªéLaunch TemplateËé∑Âèñ
      let instanceTypes = nodegroup.instanceTypes;
      if (!instanceTypes || instanceTypes.length === 0) {
        try {
          if (nodegroup.launchTemplate && nodegroup.launchTemplate.id) {
            const ltCmd = `aws ec2 describe-launch-template-versions --launch-template-id ${nodegroup.launchTemplate.id} --region ${region} --query 'LaunchTemplateVersions[0].LaunchTemplateData.InstanceType' --output json`;
            const ltResult = await execAsync(ltCmd);
            const instanceType = JSON.parse(ltResult.stdout);
            if (instanceType) {
              instanceTypes = [instanceType];
            }
          }
        } catch (ltError) {
          console.warn('Failed to get instance type from launch template:', ltError.message);
        }
      }
      
      eksNodeGroups.push({
        name: nodegroup.nodegroupName,
        status: nodegroup.status,
        instanceTypes: instanceTypes || [],
        capacityType: nodegroup.capacityType,
        scalingConfig: nodegroup.scalingConfig,
        amiType: nodegroup.amiType,
        subnets: nodegroup.subnets,
        nodeRole: nodegroup.nodeRole
      });
    }
    
    // Ëé∑ÂèñHyperPodÂÆû‰æãÁªÑ
    const hyperPodGroups = [];
    try {
      const hpClusterName = clusterName.replace('eks-cluster-', 'hp-cluster-');
      const hpCmd = `aws sagemaker describe-cluster --cluster-name ${hpClusterName} --region ${region} --output json`;
      const hpResult = await execAsync(hpCmd);
      const hpData = JSON.parse(hpResult.stdout);
      
      for (const instanceGroup of hpData.InstanceGroups || []) {
        hyperPodGroups.push({
          clusterName: hpClusterName,
          clusterArn: hpData.ClusterArn,
          name: instanceGroup.InstanceGroupName,
          status: instanceGroup.Status,
          instanceType: instanceGroup.InstanceType,
          currentCount: instanceGroup.CurrentCount,
          targetCount: instanceGroup.TargetCount,
          executionRole: instanceGroup.ExecutionRole
        });
      }
    } catch (hpError) {
      console.log('No HyperPod cluster found or error:', hpError.message);
    }
    
    res.json({
      eksNodeGroups,
      hyperPodInstanceGroups: hyperPodGroups
    });
  } catch (error) {
    console.error('Error fetching node groups:', error);
    res.status(500).json({ error: error.message });
  }
});

app.put('/api/cluster/nodegroups/:name/scale', async (req, res) => {
  try {
    const { exec } = require('child_process');
    const { promisify } = require('util');
    const execAsync = promisify(exec);
    const fs = require('fs');
    const path = require('path');
    
    const { name } = req.params;
    const { minSize, maxSize, desiredSize } = req.body;
    
    const ClusterManager = require('./cluster-manager');
    const clusterManager = new ClusterManager();
    const activeClusterName = clusterManager.getActiveCluster();
    
    if (!activeClusterName) {
      return res.status(400).json({ error: 'No active cluster found' });
    }

    // ËØªÂèñÈõÜÁæ§ÈÖçÁΩÆÊñá‰ª∂
    const configDir = clusterManager.getClusterConfigDir(activeClusterName);
    const initEnvsPath = path.join(configDir, 'init_envs');
    
    if (!fs.existsSync(initEnvsPath)) {
      return res.status(400).json({ error: 'Cluster configuration file not found' });
    }

    // Ëß£Êûêinit_envsÊñá‰ª∂ - ‰ΩøÁî®shell sourceÊñπÂºè
    const getEnvVar = async (varName) => {
      const cmd = `source ${initEnvsPath} && echo $${varName}`;
      const result = await execAsync(cmd, { shell: '/bin/bash' });
      return result.stdout.trim();
    };
    
    const clusterName = await getEnvVar('EKS_CLUSTER_NAME') || activeClusterName;
    const region = await getEnvVar('AWS_REGION') || 'us-west-2';
    
    const cmd = `aws eks update-nodegroup-config --cluster-name ${clusterName} --nodegroup-name ${name} --scaling-config minSize=${minSize},maxSize=${maxSize},desiredSize=${desiredSize} --region ${region}`;
    
    await execAsync(cmd);
    
    // WebSocketÈÄöÁü•
    broadcast({
      type: 'nodegroup_updated',
      status: 'success',
      message: `EKS node group ${name} scaling updated successfully`
    });
    
    res.json({ success: true });
  } catch (error) {
    console.error('Error updating EKS node group:', error);
    broadcast({
      type: 'nodegroup_updated',
      status: 'error',
      message: `Failed to update EKS node group: ${error.message}`
    });
    res.status(500).json({ error: error.message });
  }
});

app.put('/api/cluster/hyperpod/instances/:name/scale', async (req, res) => {
  try {
    const { exec } = require('child_process');
    const { promisify } = require('util');
    const execAsync = promisify(exec);
    const fs = require('fs');
    const path = require('path');
    
    const { name } = req.params;
    const { targetCount } = req.body;
    
    const ClusterManager = require('./cluster-manager');
    const clusterManager = new ClusterManager();
    const activeClusterName = clusterManager.getActiveCluster();
    
    if (!activeClusterName) {
      return res.status(400).json({ error: 'No active cluster found' });
    }

    // ËØªÂèñÈõÜÁæ§ÈÖçÁΩÆÊñá‰ª∂
    const configDir = clusterManager.getClusterConfigDir(activeClusterName);
    const initEnvsPath = path.join(configDir, 'init_envs');
    
    if (!fs.existsSync(initEnvsPath)) {
      return res.status(400).json({ error: 'Cluster configuration file not found' });
    }

    // Ëß£Êûêinit_envsÊñá‰ª∂ - ‰ΩøÁî®shell sourceÊñπÂºè
    const getEnvVar = async (varName) => {
      const cmd = `source ${initEnvsPath} && echo $${varName}`;
      const result = await execAsync(cmd, { shell: '/bin/bash' });
      return result.stdout.trim();
    };
    
    const clusterName = await getEnvVar('EKS_CLUSTER_NAME') || activeClusterName;
    const region = await getEnvVar('AWS_REGION') || 'us-west-2';
    const hpClusterName = clusterName.replace('eks-cluster-', 'hp-cluster-');
    
    // HyperPodÈúÄË¶ÅÂÆåÊï¥ÁöÑÂÆû‰æãÁªÑÈÖçÁΩÆÔºå‰∏çËÉΩÂè™Êõ¥Êñ∞InstanceCount
    // Êàë‰ª¨ÈúÄË¶ÅÂÖàËé∑ÂèñÂΩìÂâçÈÖçÁΩÆÔºåÁÑ∂ÂêéÊõ¥Êñ∞InstanceCount
    const getCmd = `aws sagemaker describe-cluster --cluster-name ${hpClusterName} --region ${region}`;
    const getResult = await execAsync(getCmd);
    const clusterData = JSON.parse(getResult.stdout);
    
    // ÊâæÂà∞Ë¶ÅÊõ¥Êñ∞ÁöÑÂÆû‰æãÁªÑ
    const instanceGroup = clusterData.InstanceGroups.find(ig => ig.InstanceGroupName === name);
    if (!instanceGroup) {
      throw new Error(`Instance group ${name} not found`);
    }
    
    // ÊûÑÂª∫Êõ¥Êñ∞ÂëΩ‰ª§Ôºå‰ΩøÁî®ÂÆåÊï¥ÁöÑÂÆû‰æãÁªÑÈÖçÁΩÆ
    const updateInstanceGroup = {
      InstanceGroupName: instanceGroup.InstanceGroupName,
      InstanceType: instanceGroup.InstanceType,
      InstanceCount: targetCount,
      ExecutionRole: instanceGroup.ExecutionRole,
      LifeCycleConfig: instanceGroup.LifeCycleConfig
    };
    
    // Ê∑ªÂä†ÂèØÈÄâÂèÇÊï∞
    if (instanceGroup.ThreadsPerCore) {
      updateInstanceGroup.ThreadsPerCore = instanceGroup.ThreadsPerCore;
    }
    if (instanceGroup.InstanceStorageConfigs) {
      updateInstanceGroup.InstanceStorageConfigs = instanceGroup.InstanceStorageConfigs;
    }
    
    const cmd = `aws sagemaker update-cluster --cluster-name ${hpClusterName} --instance-groups '${JSON.stringify(updateInstanceGroup)}' --region ${region}`;
    
    await execAsync(cmd);
    
    // WebSocketÈÄöÁü•
    broadcast({
      type: 'nodegroup_updated',
      status: 'success',
      message: `HyperPod instance group ${name} scaling updated successfully`
    });
    
    res.json({ success: true });
  } catch (error) {
    console.error('Error updating HyperPod instance group:', error);
    broadcast({
      type: 'nodegroup_updated',
      status: 'error',
      message: `Failed to update HyperPod instance group: ${error.message}`
    });
    res.status(500).json({ error: error.message });
  }
});

app.post('/api/cluster/hyperpod/update-software', async (req, res) => {
  try {
    const { exec } = require('child_process');
    const { promisify } = require('util');
    const execAsync = promisify(exec);
    const fs = require('fs');
    const path = require('path');
    
    const { clusterArn } = req.body;
    
    const ClusterManager = require('./cluster-manager');
    const clusterManager = new ClusterManager();
    const activeClusterName = clusterManager.getActiveCluster();
    
    if (!activeClusterName) {
      return res.status(400).json({ error: 'No active cluster found' });
    }

    // ËØªÂèñÈõÜÁæ§ÈÖçÁΩÆÊñá‰ª∂Ëé∑Âèñregion
    const configDir = clusterManager.getClusterConfigDir(activeClusterName);
    const initEnvsPath = path.join(configDir, 'init_envs');
    
    if (!fs.existsSync(initEnvsPath)) {
      return res.status(400).json({ error: 'Cluster configuration file not found' });
    }

    // Ëß£Êûêinit_envsÊñá‰ª∂ - ‰ΩøÁî®shell sourceÊñπÂºè
    const getEnvVar = async (varName) => {
      const cmd = `source ${initEnvsPath} && echo $${varName}`;
      const result = await execAsync(cmd, { shell: '/bin/bash' });
      return result.stdout.trim();
    };
    
    const region = await getEnvVar('AWS_REGION') || 'us-west-2';

    // ÊâßË°åupdate-cluster-softwareÂëΩ‰ª§
    const updateCmd = `aws sagemaker update-cluster-software --cluster-name ${clusterArn} --region ${region}`;
    
    await execAsync(updateCmd);
    
    broadcast({
      type: 'hyperpod_software_update',
      status: 'success',
      message: 'HyperPod cluster software update initiated successfully',
      clusterArn: clusterArn
    });

    res.json({ success: true, message: 'Cluster software update initiated successfully' });
  } catch (error) {
    console.error('Error updating HyperPod cluster software:', error);
    
    broadcast({
      type: 'hyperpod_software_update',
      status: 'error',
      message: `Failed to update cluster software: ${error.message}`
    });

    res.status(500).json({ error: error.message });
  }
});

console.log('Multi-cluster management APIs loaded');

// ÂºïÂÖ•CIDRÁîüÊàêÂ∑•ÂÖ∑
const CidrGenerator = require('./utils/cidrGenerator');
const CloudFormationManager = require('./utils/cloudFormationManager');
const ClusterDependencyManager = require('./utils/clusterDependencyManager');
const ClusterManager = require('./cluster-manager');
const clusterManager = new ClusterManager();

// CIDRÁîüÊàêÁõ∏ÂÖ≥API
app.get('/api/cluster/generate-cidr', async (req, res) => {
  try {
    const { region, excludeCidr } = req.query;
    
    if (!region) {
      return res.status(400).json({ error: 'AWS region is required' });
    }
    
    const cidr = await CidrGenerator.generateUniqueCidr(region, excludeCidr);
    
    res.json({
      success: true,
      cidr,
      region,
      generatedAt: new Date().toISOString()
    });
  } catch (error) {
    console.error('Error generating CIDR:', error);
    res.status(500).json({ error: error.message });
  }
});

// ÁîüÊàêÂÆåÊï¥CIDRÈÖçÁΩÆ
app.post('/api/cluster/generate-cidr-config', async (req, res) => {
  try {
    const { region, customVpcCidr } = req.body;
    
    if (!region) {
      return res.status(400).json({ error: 'AWS region is required' });
    }
    
    const cidrConfig = await CidrGenerator.generateFullCidrConfiguration(region, customVpcCidr);
    
    res.json({
      success: true,
      ...cidrConfig
    });
  } catch (error) {
    console.error('Error generating CIDR configuration:', error);
    res.status(500).json({ error: error.message });
  }
});

// È™åËØÅCIDRÊ†ºÂºèÂíåÂÜ≤Á™Å
app.post('/api/cluster/validate-cidr', async (req, res) => {
  try {
    const { cidr, region } = req.body;
    
    if (!cidr || !region) {
      return res.status(400).json({ error: 'CIDR and region are required' });
    }
    
    // È™åËØÅÊ†ºÂºè
    const isValidFormat = CidrGenerator.validateCidrFormat(cidr);
    if (!isValidFormat) {
      return res.json({
        success: false,
        valid: false,
        error: 'Invalid CIDR format'
      });
    }
    
    // Ê£ÄÊü•ÂÜ≤Á™Å
    const hasConflict = await CidrGenerator.checkCidrConflict(cidr, region);
    
    res.json({
      success: true,
      valid: !hasConflict,
      conflict: hasConflict,
      message: hasConflict ? 'CIDR conflicts with existing VPC' : 'CIDR is available'
    });
  } catch (error) {
    console.error('Error validating CIDR:', error);
    res.status(500).json({ error: error.message });
  }
});

console.log('CIDR generation APIs loaded');

// EKSÈõÜÁæ§ÂàõÂª∫Áõ∏ÂÖ≥API
app.post('/api/cluster/create-eks', async (req, res) => {
  try {
    const { clusterTag, awsRegion, customVpcCidr } = req.body;
    
    // È™åËØÅÂøÖÂ°´Â≠óÊÆµ
    if (!clusterTag || !awsRegion) {
      return res.status(400).json({ error: 'Missing required fields: clusterTag and awsRegion' });
    }
    
    // ÁîüÊàêCIDRÈÖçÁΩÆ
    const cidrConfig = await CidrGenerator.generateFullCidrConfiguration(awsRegion, customVpcCidr);
    
    // Á´ãÂç≥ÂàõÂª∫ÈõÜÁæ§ÁõÆÂΩïÂíåÁä∂ÊÄÅËÆ∞ÂΩïÔºàÂú®CloudFormationË∞ÉÁî®ÂâçÔºâ
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-').slice(0, 19);
    const stackName = `full-stack-${clusterTag}-${timestamp}`;
    
    const clusterConfig = {
      clusterTag,
      awsRegion,
      customVpcCidr: customVpcCidr || 'auto-generated'
    };
    
    // ÂàõÂª∫ÈõÜÁæ§ÁõÆÂΩïÁªìÊûÑ
    clusterManager.createClusterDirs(clusterTag);
    
    // Á´ãÂç≥‰øùÂ≠òÁî®Êà∑ËæìÂÖ•ÂíåCIDRÈÖçÁΩÆ
    const metadataDir = clusterManager.getClusterMetadataDir(clusterTag);
    const fs = require('fs');
    const path = require('path');
    
    // Ê∑ªÂä†Âà∞creating-clustersË∑üË∏™Êñá‰ª∂
    const creatingClustersPath = path.join(__dirname, '../managed_clusters_info/creating-clusters.json');
    let creatingClusters = {};
    if (fs.existsSync(creatingClustersPath)) {
      creatingClusters = JSON.parse(fs.readFileSync(creatingClustersPath, 'utf8'));
    }
    creatingClusters[clusterTag] = {
      type: 'eks',
      status: 'IN_PROGRESS',
      createdAt: new Date().toISOString(),
      stackName: stackName,
      region: awsRegion
    };
    fs.writeFileSync(creatingClustersPath, JSON.stringify(creatingClusters, null, 2));
    
    // ‰øùÂ≠òÁî®Êà∑ËæìÂÖ•‰ø°ÊÅØ
    fs.writeFileSync(
      path.join(metadataDir, 'user_input.json'),
      JSON.stringify({
        clusterTag,
        awsRegion,
        customVpcCidr: customVpcCidr || null,
        inputAt: new Date().toISOString()
      }, null, 2)
    );
    
    // ‰øùÂ≠òCIDRÈÖçÁΩÆ
    fs.writeFileSync(
      path.join(metadataDir, 'cidr_configuration.json'),
      JSON.stringify(cidrConfig, null, 2)
    );
    
    // ‰øùÂ≠òÂàõÂª∫Áä∂ÊÄÅ
    fs.writeFileSync(
      path.join(metadataDir, 'creation_status.json'),
      JSON.stringify({
        status: 'IN_PROGRESS',
        createdAt: new Date().toISOString(),
        lastUpdated: new Date().toISOString(),
        stackName: stackName,
        region: awsRegion,
        phase: 'CLOUDFORMATION_CREATING'
      }, null, 2)
    );
    
    // ÂàõÂª∫CloudFormation Stack
    const stackResult = await CloudFormationManager.createStack({
      clusterTag,
      awsRegion,
      stackName
    }, cidrConfig);
    
    // Êõ¥Êñ∞ÂàõÂª∫Áä∂ÊÄÅÔºåÊ∑ªÂä†Stack ID
    fs.writeFileSync(
      path.join(metadataDir, 'creation_status.json'),
      JSON.stringify({
        status: 'IN_PROGRESS',
        createdAt: new Date().toISOString(),
        lastUpdated: new Date().toISOString(),
        stackName: stackName,
        stackId: stackResult.stackId,
        region: awsRegion,
        phase: 'CLOUDFORMATION_IN_PROGRESS'
      }, null, 2)
    );
    
    // Êõ¥Êñ∞creating-clustersË∑üË∏™Êñá‰ª∂
    creatingClusters[clusterTag].stackId = stackResult.stackId;
    creatingClusters[clusterTag].phase = 'CLOUDFORMATION_IN_PROGRESS';
    creatingClusters[clusterTag].lastUpdated = new Date().toISOString();
    fs.writeFileSync(creatingClustersPath, JSON.stringify(creatingClusters, null, 2));
    
    await clusterManager.saveCreationConfig(clusterTag, clusterConfig, cidrConfig, stackResult);
    
    // ÂèëÈÄÅWebSocketÈÄöÁü•
    broadcast({
      type: 'cluster_creation_started',
      status: 'success',
      message: `EKS cluster creation started: ${clusterTag}`,
      clusterTag,
      stackName: stackResult.stackName
    });
    
    res.json({
      success: true,
      clusterTag,
      stackName: stackResult.stackName,
      stackId: stackResult.stackId,
      cidrConfig,
      message: 'EKS cluster creation started successfully'
    });
  } catch (error) {
    console.error('Error creating EKS cluster:', error);
    
    broadcast({
      type: 'cluster_creation_started',
      status: 'error',
      message: `Failed to create EKS cluster: ${error.message}`
    });
    
    res.status(500).json({ error: error.message });
  }
});

// ËæÖÂä©ÂáΩÊï∞ÔºöÊõ¥Êñ∞creating-clustersÁä∂ÊÄÅ
function updateCreatingClustersStatus(clusterTag, status, additionalData = {}) {
  const fs = require('fs');
  const path = require('path');
  const creatingClustersPath = path.join(__dirname, '../managed_clusters_info/creating-clusters.json');
  
  let creatingClusters = {};
  if (fs.existsSync(creatingClustersPath)) {
    creatingClusters = JSON.parse(fs.readFileSync(creatingClustersPath, 'utf8'));
  }
  
  if (creatingClusters[clusterTag]) {
    if (status === 'COMPLETED' || status === 'FAILED') {
      // ÂàõÂª∫ÂÆåÊàêÊàñÂ§±Ë¥•Ôºå‰ªéË∑üË∏™Êñá‰ª∂‰∏≠ÁßªÈô§
      delete creatingClusters[clusterTag];
    } else {
      // Êõ¥Êñ∞Áä∂ÊÄÅ
      creatingClusters[clusterTag] = {
        ...creatingClusters[clusterTag],
        status: status,
        lastUpdated: new Date().toISOString(),
        ...additionalData
      };
    }
    fs.writeFileSync(creatingClustersPath, JSON.stringify(creatingClusters, null, 2));
  }
}

// Ëé∑ÂèñÊ≠£Âú®ÂàõÂª∫ÁöÑÈõÜÁæ§ÂàóË°®
app.get('/api/cluster/creating-clusters', async (req, res) => {
  try {
    const fs = require('fs');
    const path = require('path');
    const creatingClustersPath = path.join(__dirname, '../managed_clusters_info/creating-clusters.json');
    
    if (!fs.existsSync(creatingClustersPath)) {
      return res.json({ success: true, clusters: {} });
    }
    
    const creatingClusters = JSON.parse(fs.readFileSync(creatingClustersPath, 'utf8'));
    const clustersToCleanup = [];
    
    // ‰∏∫ÊØè‰∏™ÂàõÂª∫‰∏≠ÁöÑÈõÜÁæ§Ëé∑ÂèñÊúÄÊñ∞Áä∂ÊÄÅ
    for (const [clusterTag, clusterInfo] of Object.entries(creatingClusters)) {
      if (clusterInfo.type === 'eks' && clusterInfo.stackName) {
        try {
          const stackStatus = await CloudFormationManager.getStackStatus(clusterInfo.stackName, clusterInfo.region);
          clusterInfo.currentStackStatus = stackStatus.stackStatus;
          
          // Â¶ÇÊûúÂàõÂª∫ÂÆåÊàêÊàñÂ§±Ë¥•ÔºåÊõ¥Êñ∞Áä∂ÊÄÅ
          if (stackStatus.stackStatus === 'CREATE_COMPLETE') {
            // ÂÖàÊõ¥Êñ∞Áä∂ÊÄÅ‰∏∫ÈÖçÁΩÆ‰æùËµñÈò∂ÊÆµ
            updateCreatingClustersStatus(clusterTag, 'CONFIGURING_DEPENDENCIES');
            
            // ÈÖçÁΩÆÈõÜÁæ§‰æùËµñÔºàhelmÁ≠âÔºâ
            await configureClusterDependencies(clusterTag);
            
            // ÈÖçÁΩÆÂÆåÊàêÂêéÔºåÊ≥®ÂÜåÈõÜÁæ§Âà∞ÂèØÈÄâÂàóË°®
            await registerCompletedCluster(clusterTag);
          } else if (stackStatus.stackStatus.includes('FAILED') || stackStatus.stackStatus.includes('ROLLBACK')) {
            updateCreatingClustersStatus(clusterTag, 'FAILED', { error: stackStatus.stackStatusReason });
          }
        } catch (error) {
          console.error(`Error checking status for cluster ${clusterTag}:`, error);
          
          // Â¶ÇÊûúCloudFormation Stack‰∏çÂ≠òÂú®ÔºàË¢´ÊâãÂä®Âà†Èô§ÔºâÔºåÊ†áËÆ∞‰∏∫ÈúÄË¶ÅÊ∏ÖÁêÜ
          if (error.message.includes('does not exist') || error.message.includes('ValidationError')) {
            console.log(`CloudFormation stack ${clusterInfo.stackName} no longer exists, cleaning up metadata`);
            clustersToCleanup.push(clusterTag);
          }
        }
      }
    }
    
    // Ê∏ÖÁêÜÊú¨Âú∞metadata
    for (const clusterTag of clustersToCleanup) {
      cleanupCreatingMetadata(clusterTag);
    }
    
    // ÈáçÊñ∞ËØªÂèñÊ∏ÖÁêÜÂêéÁöÑÁä∂ÊÄÅ
    const updatedCreatingClusters = fs.existsSync(creatingClustersPath) 
      ? JSON.parse(fs.readFileSync(creatingClustersPath, 'utf8'))
      : {};
    
    res.json({ success: true, clusters: updatedCreatingClusters });
  } catch (error) {
    console.error('Error getting creating clusters:', error);
    res.status(500).json({ error: error.message });
  }
});

// ÈÖçÁΩÆÈõÜÁæ§‰æùËµñÔºàhelmÁ≠âÔºâ
async function configureClusterDependencies(clusterTag) {
  try {
    console.log(`Configuring dependencies for cluster: ${clusterTag}`);
    
    // ‰ΩøÁî®ClusterDependencyManagerËøõË°åÈÖçÁΩÆ
    await ClusterDependencyManager.configureClusterDependencies(clusterTag, clusterManager);
    
    console.log(`Successfully configured dependencies for cluster: ${clusterTag}`);
    
    // Êõ¥Êñ∞Áä∂ÊÄÅ‰∏∫ÂÆåÊàê
    updateCreatingClustersStatus(clusterTag, 'COMPLETED');
    
  } catch (error) {
    console.error(`Error configuring dependencies for cluster ${clusterTag}:`, error);
    updateCreatingClustersStatus(clusterTag, 'DEPENDENCY_CONFIG_FAILED', { error: error.message });
    throw error;
  }
}

// Ê≥®ÂÜåÂÆåÊàêÁöÑÈõÜÁæ§Âà∞ÂèØÈÄâÂàóË°®
async function registerCompletedCluster(clusterTag) {
  try {
    console.log(`Registering completed cluster: ${clusterTag}`);
    
    const fs = require('fs');
    const path = require('path');
    
    // ËØªÂèñÂàõÂª∫Êó∂ÁöÑmetadata
    const metadataDir = clusterManager.getClusterMetadataDir(clusterTag);
    const creationMetadataPath = path.join(metadataDir, 'creation_metadata.json');
    
    if (!fs.existsSync(creationMetadataPath)) {
      console.error(`Creation metadata not found for cluster: ${clusterTag}`);
      return;
    }
    
    const creationMetadata = JSON.parse(fs.readFileSync(creationMetadataPath, 'utf8'));
    
    // ÁîüÊàêcluster_info.jsonÔºàÂÖºÂÆπÁé∞ÊúâÊ†ºÂºèÔºâ
    const clusterInfo = {
      clusterTag: clusterTag,
      region: creationMetadata.userConfig.awsRegion,
      status: 'active',
      type: 'created',
      createdAt: creationMetadata.createdAt,
      lastModified: new Date().toISOString(),
      source: 'ui-panel-creation',
      cloudFormation: {
        stackName: creationMetadata.cloudFormation.stackName,
        stackId: creationMetadata.cloudFormation.stackId
      }
    };
    
    // ‰øùÂ≠òcluster_info.json
    const clusterInfoPath = path.join(metadataDir, 'cluster_info.json');
    fs.writeFileSync(clusterInfoPath, JSON.stringify(clusterInfo, null, 2));
    
    console.log(`Successfully registered cluster: ${clusterTag}`);
    
    // ÂèëÈÄÅWebSocketÈÄöÁü•
    broadcast({
      type: 'cluster_creation_completed',
      status: 'success',
      message: `EKS cluster created and registered: ${clusterTag}`,
      clusterTag: clusterTag
    });
    
  } catch (error) {
    console.error(`Failed to register completed cluster ${clusterTag}:`, error);
  }
}

// Ê∏ÖÁêÜcreating metadataÔºà‰∏çËß¶Á¢∞CloudFormationÔºâ
function cleanupCreatingMetadata(clusterTag) {
  const fs = require('fs');
  const path = require('path');
  
  try {
    console.log(`Cleaning up creating metadata for: ${clusterTag}`);
    
    // ‰ªécreating-clusters.json‰∏≠ÁßªÈô§
    const creatingClustersPath = path.join(__dirname, '../managed_clusters_info/creating-clusters.json');
    if (fs.existsSync(creatingClustersPath)) {
      const creatingClusters = JSON.parse(fs.readFileSync(creatingClustersPath, 'utf8'));
      delete creatingClusters[clusterTag];
      fs.writeFileSync(creatingClustersPath, JSON.stringify(creatingClusters, null, 2));
    }
    
    // Âà†Èô§ÈõÜÁæ§ÁõÆÂΩïÔºàÊÅ¢Â§çÂà∞Á©∫ÁôΩÁä∂ÊÄÅÔºâ
    const clusterDir = path.join(__dirname, '../managed_clusters_info', clusterTag);
    if (fs.existsSync(clusterDir)) {
      fs.rmSync(clusterDir, { recursive: true, force: true });
      console.log(`Removed cluster directory: ${clusterDir}`);
    }
    
    console.log(`Successfully cleaned up metadata for cluster: ${clusterTag}`);
    
  } catch (error) {
    console.error(`Error cleaning up metadata for cluster ${clusterTag}:`, error);
  }
}

// Ê£ÄÊü•ÈõÜÁæ§‰æùËµñÈÖçÁΩÆÁä∂ÊÄÅ
app.get('/api/cluster/dependency-status/:clusterTag', async (req, res) => {
  try {
    const { clusterTag } = req.params;
    
    const clusterDir = clusterManager.getClusterDir(clusterTag);
    const configDir = path.join(clusterDir, 'config');
    
    if (!fs.existsSync(configDir)) {
      return res.status(404).json({ error: 'Cluster not found' });
    }
    
    const status = await ClusterDependencyManager.checkDependencyStatus(configDir);
    
    res.json({
      success: true,
      clusterTag,
      dependencyStatus: status
    });
    
  } catch (error) {
    console.error('Error checking dependency status:', error);
    res.status(500).json({ error: error.message });
  }
});

// ÊâãÂä®ÈáçÊñ∞ÈÖçÁΩÆÈõÜÁæ§‰æùËµñÔºàÁî®‰∫éË∞ÉËØïÔºâ
app.post('/api/cluster/reconfigure-dependencies/:clusterTag', async (req, res) => {
  try {
    const { clusterTag } = req.params;
    
    console.log(`Manual reconfiguration requested for cluster: ${clusterTag}`);
    
    // ÂÖàÊ∏ÖÁêÜÁé∞ÊúâÈÖçÁΩÆ
    const clusterDir = clusterManager.getClusterDir(clusterTag);
    const configDir = path.join(clusterDir, 'config');
    
    await ClusterDependencyManager.cleanupDependencies(configDir);
    
    // ÈáçÊñ∞ÈÖçÁΩÆ
    await ClusterDependencyManager.configureClusterDependencies(clusterTag, clusterManager);
    
    res.json({
      success: true,
      message: `Successfully reconfigured dependencies for cluster: ${clusterTag}`
    });
    
  } catch (error) {
    console.error('Error reconfiguring dependencies:', error);
    res.status(500).json({ error: error.message });
  }
});

// Ëé∑ÂèñÈõÜÁæ§ÂàõÂª∫Áä∂ÊÄÅ
app.get('/api/cluster/creation-status/:clusterTag', async (req, res) => {
  try {
    const { clusterTag } = req.params;
    const fs = require('fs');
    const path = require('path');
    
    // ËØªÂèñÂàõÂª∫metadataËé∑ÂèñregionÂíåstack‰ø°ÊÅØ
    const metadataDir = clusterManager.getClusterMetadataDir(clusterTag);
    const creationStatusPath = path.join(metadataDir, 'creation_status.json');
    
    if (!fs.existsSync(creationStatusPath)) {
      return res.status(404).json({ error: 'Creation status not found' });
    }
    
    const creationStatus = JSON.parse(fs.readFileSync(creationStatusPath, 'utf8'));
    const stackName = creationStatus.stackName;
    const region = creationStatus.region;
    
    if (!stackName || !region) {
      return res.status(400).json({ error: 'Missing stack name or region in metadata' });
    }
    
    const stackStatus = await CloudFormationManager.getStackStatus(stackName, region);
    
    res.json({
      success: true,
      clusterTag,
      stackName,
      region,
      ...stackStatus
    });
  } catch (error) {
    console.error('Error getting cluster creation status:', error);
    res.status(500).json({ error: error.message });
  }
});

// Ëé∑ÂèñÈõÜÁæ§ÂàõÂª∫Êó•Âøó
app.get('/api/cluster/creation-logs/:clusterTag', async (req, res) => {
  try {
    const { clusterTag } = req.params;
    
    // ËØªÂèñÈõÜÁæ§ÈÖçÁΩÆ
    const clusterInfo = await clusterManager.getClusterInfo(clusterTag);
    if (!clusterInfo) {
      return res.status(404).json({ error: 'Cluster not found' });
    }
    
    const stackName = `full-stack-${clusterTag}`;
    const events = await CloudFormationManager.getStackEvents(stackName, clusterInfo.awsRegion);
    
    res.json({
      success: true,
      clusterTag,
      stackName,
      events
    });
  } catch (error) {
    console.error('Error getting cluster creation logs:', error);
    res.status(500).json({ error: error.message });
  }
});

// ÂèñÊ∂àÈõÜÁæ§ÂàõÂª∫
app.post('/api/cluster/cancel-creation/:clusterTag', async (req, res) => {
  try {
    const { clusterTag } = req.params;
    
    // ËØªÂèñÈõÜÁæ§ÈÖçÁΩÆ
    const clusterInfo = await clusterManager.getClusterInfo(clusterTag);
    if (!clusterInfo) {
      return res.status(404).json({ error: 'Cluster not found' });
    }
    
    const stackName = `full-stack-${clusterTag}`;
    const result = await CloudFormationManager.cancelStackCreation(stackName, clusterInfo.awsRegion);
    
    // ÂèëÈÄÅWebSocketÈÄöÁü•
    broadcast({
      type: 'cluster_creation_cancelled',
      status: 'success',
      message: `Cluster creation cancelled: ${clusterTag}`,
      clusterTag
    });
    
    res.json({
      success: true,
      clusterTag,
      ...result
    });
  } catch (error) {
    console.error('Error cancelling cluster creation:', error);
    
    broadcast({
      type: 'cluster_creation_cancelled',
      status: 'error',
      message: `Failed to cancel cluster creation: ${error.message}`
    });
    
    res.status(500).json({ error: error.message });
  }
});

console.log('EKS cluster creation APIs loaded');

app.listen(PORT, () => {
  console.log('üöÄ ========================================');
  console.log('üöÄ HyperPod InstantStart Server Started');
  console.log('üöÄ ========================================');
  console.log(`üì° HTTP Server: http://localhost:${PORT}`);
  console.log(`üîå WebSocket Server: ws://localhost:${WS_PORT}`);
  console.log(`üåê Multi-cluster management: enabled`);
  console.log(`‚è∞ Server started at: ${new Date().toISOString()}`);
  console.log(`üñ•Ô∏è  Node.js version: ${process.version}`);
  console.log(`üíæ Memory usage: ${Math.round(process.memoryUsage().heapUsed / 1024 / 1024)}MB`);
  console.log(`üîß Environment: ${process.env.NODE_ENV || 'development'}`);
  console.log('üöÄ ========================================');
  console.log('‚úÖ Server is ready to accept connections');
});
